{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02285e6",
   "metadata": {
    "id": "a02285e6"
   },
   "source": [
    "# Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc5329",
   "metadata": {
    "id": "bdcc5329"
   },
   "source": [
    "Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
   "metadata": {
    "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/nd2745/.local/lib/python3.9/site-packages (4.50.3)\n",
      "Requirement already satisfied: datasets in /home/nd2745/.local/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: evaluate in /home/nd2745/.local/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: accelerate in /home/nd2745/.local/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: peft in /home/nd2745/.local/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: trl in /home/nd2745/.local/lib/python3.9/site-packages (0.16.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/nd2745/.local/lib/python3.9/site-packages (0.45.5)\n",
      "Requirement already satisfied: filelock in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nd2745/.local/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/nd2745/.local/lib/python3.9/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/nd2745/.local/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/nd2745/.local/lib/python3.9/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/nd2745/.local/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/nd2745/.local/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/nd2745/.local/lib/python3.9/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/nd2745/.local/lib/python3.9/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: psutil in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/nd2745/.local/lib/python3.9/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: rich in /home/nd2745/.local/lib/python3.9/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/nd2745/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/nd2745/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: networkx in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/nd2745/.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nd2745/.local/lib/python3.9/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nd2745/.local/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nd2745/.local/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/nd2745/.local/lib/python3.9/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from rich->trl) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/nd2745/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/nd2745/.local/lib/python3.9/site-packages (7.352.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate accelerate peft trl bitsandbytes\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263",
   "metadata": {
    "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nd2745/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import load_dataset, Dataset, ClassLabel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6e377",
   "metadata": {
    "id": "59d6e377"
   },
   "source": [
    "## Load Tokenizer and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f42747-f551-40a5-a95f-7affb1eba4a3",
   "metadata": {
    "id": "21f42747-f551-40a5-a95f-7affb1eba4a3"
   },
   "outputs": [],
   "source": [
    "base_model = 'roberta-base'\n",
    "\n",
    "dataset = load_dataset('ag_news', split='train')\n",
    "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True,  remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
   "metadata": {
    "id": "9e07f641-bec0-43a6-8c26-510d7642916a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels: 4\n",
      "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
     ]
    }
   ],
   "source": [
    "# Extract the number of classess and their names\n",
    "num_labels = dataset.features['label'].num_classes\n",
    "class_names = dataset.features[\"label\"].names\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "# Create an id2label mapping\n",
    "# We will need this for our classifier.\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e24afd",
   "metadata": {
    "id": "c9e24afd"
   },
   "source": [
    "## Load Pre-trained Model\n",
    "Set up config for pretrained model and download it from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c",
   "metadata": {
    "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    id2label=id2label)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265839d-a088-4693-8474-862641de11ed",
   "metadata": {
    "id": "f265839d-a088-4693-8474-862641de11ed"
   },
   "source": [
    "## Anything from here on can be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7413430-be57-482b-856e-36bd4ba799df",
   "metadata": {
    "id": "e7413430-be57-482b-856e-36bd4ba799df"
   },
   "outputs": [],
   "source": [
    "# Split the original training set\n",
    "split_datasets = tokenized_dataset.train_test_split(test_size=640, seed=42)\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652452e3",
   "metadata": {
    "id": "652452e3"
   },
   "source": [
    "## Setup LoRA Config\n",
    "Setup PEFT config and get peft model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876",
   "metadata": {
    "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876"
   },
   "outputs": [],
   "source": [
    "# PEFT Config\n",
    "peft_config = LoraConfig(\n",
    "    r=21,\n",
    "    lora_alpha=40,\n",
    "    lora_dropout=0,\n",
    "    bias = 'lora_only',\n",
    "    target_modules = ['query'],\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec2739d-76b6-4fde-91c2-0fc49e1884b0",
   "metadata": {
    "id": "6ec2739d-76b6-4fde-91c2-0fc49e1884b0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=21, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=21, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f",
   "metadata": {
    "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f"
   },
   "outputs": [],
   "source": [
    "# print(\"Trainable parameters:\")\n",
    "# for name, param in peft_model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b",
   "metadata": {
    "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Model\n",
      "trainable params: 989,956 || all params: 125,629,448 || trainable%: 0.7880\n"
     ]
    }
   ],
   "source": [
    "print('PEFT Model')\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12284b58",
   "metadata": {
    "id": "12284b58"
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1",
   "metadata": {
    "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1"
   },
   "outputs": [],
   "source": [
    "# To track evaluation accuracy during training\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "768b4917-65de-4e55-ae7f-698e287535d4",
   "metadata": {
    "id": "768b4917-65de-4e55-ae7f-698e287535d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nd2745/.local/lib/python3.9/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup Training args\n",
    "output_dir = \"results_trial\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",              # ensure saving\n",
    "    save_total_limit=1,                 # optional: save last only\n",
    "    learning_rate=0.001,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=None,\n",
    "    logging_steps=100,\n",
    "    disable_tqdm=True\n",
    ")\n",
    "\n",
    "def get_trainer(model):\n",
    "      return  Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          compute_metrics=compute_metrics,\n",
    "          train_dataset=train_dataset,\n",
    "          eval_dataset=eval_dataset,\n",
    "          data_collator=data_collator,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b848278",
   "metadata": {
    "id": "9b848278"
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
   "metadata": {
    "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6088, 'grad_norm': 0.5143557190895081, 'learning_rate': 0.0009986595174262735, 'epoch': 0.013404825737265416}\n",
      "{'loss': 0.3564, 'grad_norm': 2.1240227222442627, 'learning_rate': 0.0009973190348525468, 'epoch': 0.02680965147453083}\n",
      "{'loss': 0.3757, 'grad_norm': 1.817781686782837, 'learning_rate': 0.0009959785522788203, 'epoch': 0.040214477211796246}\n",
      "{'loss': 0.3041, 'grad_norm': 2.3164684772491455, 'learning_rate': 0.0009946380697050939, 'epoch': 0.05361930294906166}\n",
      "{'loss': 0.3366, 'grad_norm': 1.362421989440918, 'learning_rate': 0.0009932975871313674, 'epoch': 0.06702412868632708}\n",
      "{'loss': 0.3102, 'grad_norm': 2.737419366836548, 'learning_rate': 0.0009919571045576407, 'epoch': 0.08042895442359249}\n",
      "{'loss': 0.3163, 'grad_norm': 0.7768217325210571, 'learning_rate': 0.0009906166219839142, 'epoch': 0.0938337801608579}\n",
      "{'loss': 0.3309, 'grad_norm': 1.783843994140625, 'learning_rate': 0.0009892761394101877, 'epoch': 0.10723860589812333}\n",
      "{'loss': 0.3123, 'grad_norm': 3.7931172847747803, 'learning_rate': 0.0009879356568364612, 'epoch': 0.12064343163538874}\n",
      "{'loss': 0.3009, 'grad_norm': 1.834359049797058, 'learning_rate': 0.0009865951742627345, 'epoch': 0.13404825737265416}\n",
      "{'loss': 0.3018, 'grad_norm': 1.9818559885025024, 'learning_rate': 0.000985254691689008, 'epoch': 0.14745308310991956}\n",
      "{'loss': 0.2948, 'grad_norm': 1.430195689201355, 'learning_rate': 0.0009839142091152815, 'epoch': 0.16085790884718498}\n",
      "{'loss': 0.3399, 'grad_norm': 1.660277009010315, 'learning_rate': 0.000982573726541555, 'epoch': 0.1742627345844504}\n",
      "{'loss': 0.2733, 'grad_norm': 1.2511934041976929, 'learning_rate': 0.0009812332439678283, 'epoch': 0.1876675603217158}\n",
      "{'loss': 0.3027, 'grad_norm': 3.711257219314575, 'learning_rate': 0.0009798927613941018, 'epoch': 0.20107238605898123}\n",
      "{'loss': 0.3196, 'grad_norm': 0.46125808358192444, 'learning_rate': 0.0009785522788203754, 'epoch': 0.21447721179624665}\n",
      "{'loss': 0.2602, 'grad_norm': 1.6279394626617432, 'learning_rate': 0.0009772117962466489, 'epoch': 0.22788203753351208}\n",
      "{'loss': 0.2848, 'grad_norm': 2.5111546516418457, 'learning_rate': 0.0009758713136729223, 'epoch': 0.24128686327077747}\n",
      "{'loss': 0.2961, 'grad_norm': 2.9515790939331055, 'learning_rate': 0.0009745308310991957, 'epoch': 0.2546916890080429}\n",
      "{'loss': 0.3062, 'grad_norm': 0.7156192660331726, 'learning_rate': 0.0009731903485254692, 'epoch': 0.2680965147453083}\n",
      "{'loss': 0.2929, 'grad_norm': 0.9835956692695618, 'learning_rate': 0.0009718498659517426, 'epoch': 0.28150134048257375}\n",
      "{'loss': 0.2981, 'grad_norm': 2.8488028049468994, 'learning_rate': 0.0009705093833780161, 'epoch': 0.2949061662198391}\n",
      "{'loss': 0.2724, 'grad_norm': 3.113553524017334, 'learning_rate': 0.0009691689008042895, 'epoch': 0.30831099195710454}\n",
      "{'loss': 0.3062, 'grad_norm': 2.8612022399902344, 'learning_rate': 0.000967828418230563, 'epoch': 0.32171581769436997}\n",
      "{'loss': 0.2812, 'grad_norm': 3.0288312435150146, 'learning_rate': 0.0009664879356568364, 'epoch': 0.3351206434316354}\n",
      "{'loss': 0.2909, 'grad_norm': 4.894003391265869, 'learning_rate': 0.00096514745308311, 'epoch': 0.3485254691689008}\n",
      "{'loss': 0.2764, 'grad_norm': 4.452587604522705, 'learning_rate': 0.0009638069705093834, 'epoch': 0.36193029490616624}\n",
      "{'loss': 0.2723, 'grad_norm': 3.6857123374938965, 'learning_rate': 0.0009624664879356569, 'epoch': 0.3753351206434316}\n",
      "{'loss': 0.2984, 'grad_norm': 2.555940628051758, 'learning_rate': 0.0009611260053619303, 'epoch': 0.38873994638069703}\n",
      "{'loss': 0.2806, 'grad_norm': 0.9496513605117798, 'learning_rate': 0.0009597855227882038, 'epoch': 0.40214477211796246}\n",
      "{'loss': 0.3019, 'grad_norm': 2.6852190494537354, 'learning_rate': 0.0009584450402144772, 'epoch': 0.4155495978552279}\n",
      "{'loss': 0.2697, 'grad_norm': 3.1353518962860107, 'learning_rate': 0.0009571045576407507, 'epoch': 0.4289544235924933}\n",
      "{'loss': 0.2626, 'grad_norm': 3.256772518157959, 'learning_rate': 0.0009557640750670241, 'epoch': 0.44235924932975873}\n",
      "{'loss': 0.2478, 'grad_norm': 0.5023141503334045, 'learning_rate': 0.0009544235924932976, 'epoch': 0.45576407506702415}\n",
      "{'loss': 0.2687, 'grad_norm': 2.471287727355957, 'learning_rate': 0.000953083109919571, 'epoch': 0.4691689008042895}\n",
      "{'loss': 0.2857, 'grad_norm': 3.8575620651245117, 'learning_rate': 0.0009517426273458445, 'epoch': 0.48257372654155495}\n",
      "{'loss': 0.2579, 'grad_norm': 8.132043838500977, 'learning_rate': 0.0009504021447721179, 'epoch': 0.4959785522788204}\n",
      "{'loss': 0.2503, 'grad_norm': 1.5270657539367676, 'learning_rate': 0.0009490616621983915, 'epoch': 0.5093833780160858}\n",
      "{'loss': 0.2908, 'grad_norm': 5.853214740753174, 'learning_rate': 0.0009477211796246649, 'epoch': 0.5227882037533512}\n",
      "{'loss': 0.2763, 'grad_norm': 3.966817617416382, 'learning_rate': 0.0009463806970509384, 'epoch': 0.5361930294906166}\n",
      "{'loss': 0.2828, 'grad_norm': 0.5179939866065979, 'learning_rate': 0.0009450402144772118, 'epoch': 0.5495978552278821}\n",
      "{'loss': 0.2813, 'grad_norm': 2.963493824005127, 'learning_rate': 0.0009436997319034852, 'epoch': 0.5630026809651475}\n",
      "{'loss': 0.2758, 'grad_norm': 3.3658924102783203, 'learning_rate': 0.0009423592493297587, 'epoch': 0.5764075067024129}\n",
      "{'loss': 0.2839, 'grad_norm': 6.701543807983398, 'learning_rate': 0.0009410187667560321, 'epoch': 0.5898123324396782}\n",
      "{'loss': 0.2859, 'grad_norm': 1.8575472831726074, 'learning_rate': 0.0009396782841823056, 'epoch': 0.6032171581769437}\n",
      "{'loss': 0.2772, 'grad_norm': 3.4097073078155518, 'learning_rate': 0.000938337801608579, 'epoch': 0.6166219839142091}\n",
      "{'loss': 0.2701, 'grad_norm': 3.0596415996551514, 'learning_rate': 0.0009369973190348525, 'epoch': 0.6300268096514745}\n",
      "{'loss': 0.3219, 'grad_norm': 2.8692755699157715, 'learning_rate': 0.0009356568364611259, 'epoch': 0.6434316353887399}\n",
      "{'loss': 0.3036, 'grad_norm': 8.786935806274414, 'learning_rate': 0.0009343163538873995, 'epoch': 0.6568364611260054}\n",
      "{'loss': 0.2918, 'grad_norm': 7.968740463256836, 'learning_rate': 0.0009329758713136729, 'epoch': 0.6702412868632708}\n",
      "{'loss': 0.2534, 'grad_norm': 1.0267974138259888, 'learning_rate': 0.0009316353887399464, 'epoch': 0.6836461126005362}\n",
      "{'loss': 0.2855, 'grad_norm': 5.1525349617004395, 'learning_rate': 0.0009302949061662198, 'epoch': 0.6970509383378016}\n",
      "{'loss': 0.2304, 'grad_norm': 2.7644143104553223, 'learning_rate': 0.0009289544235924933, 'epoch': 0.710455764075067}\n",
      "{'loss': 0.2645, 'grad_norm': 5.435939788818359, 'learning_rate': 0.0009276139410187667, 'epoch': 0.7238605898123325}\n",
      "{'loss': 0.2734, 'grad_norm': 1.643502950668335, 'learning_rate': 0.0009262734584450402, 'epoch': 0.7372654155495979}\n",
      "{'loss': 0.3149, 'grad_norm': 3.5872461795806885, 'learning_rate': 0.0009249329758713136, 'epoch': 0.7506702412868632}\n",
      "{'loss': 0.2677, 'grad_norm': 2.465574026107788, 'learning_rate': 0.0009235924932975871, 'epoch': 0.7640750670241286}\n",
      "{'loss': 0.2794, 'grad_norm': 3.793444871902466, 'learning_rate': 0.0009222520107238605, 'epoch': 0.7774798927613941}\n",
      "{'loss': 0.2925, 'grad_norm': 9.533592224121094, 'learning_rate': 0.000920911528150134, 'epoch': 0.7908847184986595}\n",
      "{'loss': 0.2893, 'grad_norm': 1.8617610931396484, 'learning_rate': 0.0009195710455764074, 'epoch': 0.8042895442359249}\n",
      "{'loss': 0.2459, 'grad_norm': 3.240910768508911, 'learning_rate': 0.000918230563002681, 'epoch': 0.8176943699731903}\n",
      "{'loss': 0.2788, 'grad_norm': 0.4852955639362335, 'learning_rate': 0.0009168900804289544, 'epoch': 0.8310991957104558}\n",
      "{'loss': 0.2978, 'grad_norm': 5.287249565124512, 'learning_rate': 0.000915549597855228, 'epoch': 0.8445040214477212}\n",
      "{'loss': 0.2863, 'grad_norm': 6.1506218910217285, 'learning_rate': 0.0009142091152815014, 'epoch': 0.8579088471849866}\n",
      "{'loss': 0.2877, 'grad_norm': 7.59546422958374, 'learning_rate': 0.0009128686327077749, 'epoch': 0.871313672922252}\n",
      "{'loss': 0.273, 'grad_norm': 4.000266075134277, 'learning_rate': 0.0009115281501340483, 'epoch': 0.8847184986595175}\n",
      "{'loss': 0.3007, 'grad_norm': 16.022703170776367, 'learning_rate': 0.0009101876675603218, 'epoch': 0.8981233243967829}\n",
      "{'loss': 0.2822, 'grad_norm': 11.39790153503418, 'learning_rate': 0.0009088471849865952, 'epoch': 0.9115281501340483}\n",
      "{'loss': 0.2887, 'grad_norm': 5.731003761291504, 'learning_rate': 0.0009075067024128687, 'epoch': 0.9249329758713136}\n",
      "{'loss': 0.3108, 'grad_norm': 13.13520336151123, 'learning_rate': 0.0009061662198391421, 'epoch': 0.938337801608579}\n",
      "{'loss': 0.2583, 'grad_norm': 3.542102098464966, 'learning_rate': 0.0009048257372654157, 'epoch': 0.9517426273458445}\n",
      "{'loss': 0.2842, 'grad_norm': 4.2888078689575195, 'learning_rate': 0.0009034852546916891, 'epoch': 0.9651474530831099}\n",
      "{'loss': 0.2646, 'grad_norm': 7.516173839569092, 'learning_rate': 0.0009021447721179626, 'epoch': 0.9785522788203753}\n",
      "{'loss': 0.3389, 'grad_norm': 6.335692882537842, 'learning_rate': 0.000900804289544236, 'epoch': 0.9919571045576407}\n",
      "{'eval_loss': 0.30145496129989624, 'eval_accuracy': 0.90625, 'eval_runtime': 2.6307, 'eval_samples_per_second': 243.279, 'eval_steps_per_second': 3.801, 'epoch': 1.0}\n",
      "{'loss': 0.3205, 'grad_norm': 9.425041198730469, 'learning_rate': 0.0008994638069705095, 'epoch': 1.0053619302949062}\n",
      "{'loss': 0.3272, 'grad_norm': 2.0022919178009033, 'learning_rate': 0.0008981233243967829, 'epoch': 1.0187667560321716}\n",
      "{'loss': 0.288, 'grad_norm': 11.215620040893555, 'learning_rate': 0.0008967828418230564, 'epoch': 1.032171581769437}\n",
      "{'loss': 0.289, 'grad_norm': 7.34700345993042, 'learning_rate': 0.0008954423592493298, 'epoch': 1.0455764075067024}\n",
      "{'loss': 0.3059, 'grad_norm': 5.64016056060791, 'learning_rate': 0.0008941018766756033, 'epoch': 1.0589812332439679}\n",
      "{'loss': 0.3431, 'grad_norm': 1.5066944360733032, 'learning_rate': 0.0008927613941018767, 'epoch': 1.0723860589812333}\n",
      "{'loss': 0.2809, 'grad_norm': 3.4236042499542236, 'learning_rate': 0.0008914209115281502, 'epoch': 1.0857908847184987}\n",
      "{'loss': 0.2869, 'grad_norm': 6.6735968589782715, 'learning_rate': 0.0008900804289544236, 'epoch': 1.0991957104557641}\n",
      "{'loss': 0.2807, 'grad_norm': 2.5750536918640137, 'learning_rate': 0.0008887399463806972, 'epoch': 1.1126005361930296}\n",
      "{'loss': 0.3176, 'grad_norm': 3.25970721244812, 'learning_rate': 0.0008873994638069706, 'epoch': 1.126005361930295}\n",
      "{'loss': 0.2792, 'grad_norm': 6.430830478668213, 'learning_rate': 0.000886058981233244, 'epoch': 1.1394101876675604}\n",
      "{'loss': 0.296, 'grad_norm': 7.625263690948486, 'learning_rate': 0.0008847184986595175, 'epoch': 1.1528150134048256}\n",
      "{'loss': 0.293, 'grad_norm': 3.368878126144409, 'learning_rate': 0.0008833780160857909, 'epoch': 1.1662198391420913}\n",
      "{'loss': 0.3046, 'grad_norm': 8.105396270751953, 'learning_rate': 0.0008820375335120644, 'epoch': 1.1796246648793565}\n",
      "{'loss': 0.3126, 'grad_norm': 11.539833068847656, 'learning_rate': 0.0008806970509383378, 'epoch': 1.193029490616622}\n",
      "{'loss': 0.3009, 'grad_norm': 11.241273880004883, 'learning_rate': 0.0008793565683646113, 'epoch': 1.2064343163538873}\n",
      "{'loss': 0.2906, 'grad_norm': 3.829840660095215, 'learning_rate': 0.0008780160857908847, 'epoch': 1.2198391420911527}\n",
      "{'loss': 0.2941, 'grad_norm': 18.307260513305664, 'learning_rate': 0.0008766756032171582, 'epoch': 1.2332439678284182}\n",
      "{'loss': 0.296, 'grad_norm': 9.999373435974121, 'learning_rate': 0.0008753351206434316, 'epoch': 1.2466487935656836}\n",
      "{'loss': 0.2849, 'grad_norm': 7.472064971923828, 'learning_rate': 0.0008739946380697052, 'epoch': 1.260053619302949}\n",
      "{'loss': 0.3011, 'grad_norm': 3.1268417835235596, 'learning_rate': 0.0008726541554959786, 'epoch': 1.2734584450402144}\n",
      "{'loss': 0.3029, 'grad_norm': 9.384374618530273, 'learning_rate': 0.0008713136729222521, 'epoch': 1.2868632707774799}\n",
      "{'loss': 0.333, 'grad_norm': 10.625448226928711, 'learning_rate': 0.0008699731903485255, 'epoch': 1.3002680965147453}\n",
      "{'loss': 0.3188, 'grad_norm': 23.031578063964844, 'learning_rate': 0.000868632707774799, 'epoch': 1.3136729222520107}\n",
      "{'loss': 0.2864, 'grad_norm': 4.012883186340332, 'learning_rate': 0.0008672922252010724, 'epoch': 1.3270777479892761}\n",
      "{'loss': 0.2766, 'grad_norm': 26.732650756835938, 'learning_rate': 0.0008659517426273459, 'epoch': 1.3404825737265416}\n",
      "{'loss': 0.2868, 'grad_norm': 11.990745544433594, 'learning_rate': 0.0008646112600536193, 'epoch': 1.353887399463807}\n",
      "{'loss': 0.3253, 'grad_norm': 3.669842004776001, 'learning_rate': 0.0008632707774798928, 'epoch': 1.3672922252010724}\n",
      "{'loss': 0.3422, 'grad_norm': 7.484220027923584, 'learning_rate': 0.0008619302949061662, 'epoch': 1.3806970509383378}\n",
      "{'loss': 0.3155, 'grad_norm': 6.242254257202148, 'learning_rate': 0.0008605898123324397, 'epoch': 1.3941018766756033}\n",
      "{'loss': 0.3327, 'grad_norm': 9.310912132263184, 'learning_rate': 0.0008592493297587131, 'epoch': 1.4075067024128687}\n",
      "{'loss': 0.3591, 'grad_norm': 9.672098159790039, 'learning_rate': 0.0008579088471849867, 'epoch': 1.420911528150134}\n",
      "{'loss': 0.3683, 'grad_norm': 5.227114200592041, 'learning_rate': 0.0008565683646112601, 'epoch': 1.4343163538873995}\n",
      "{'loss': 0.3228, 'grad_norm': 4.724673271179199, 'learning_rate': 0.0008552278820375336, 'epoch': 1.447721179624665}\n",
      "{'loss': 0.3541, 'grad_norm': 15.90630054473877, 'learning_rate': 0.000853887399463807, 'epoch': 1.4611260053619302}\n",
      "{'loss': 0.3675, 'grad_norm': 7.481717109680176, 'learning_rate': 0.0008525469168900805, 'epoch': 1.4745308310991958}\n",
      "{'loss': 0.3142, 'grad_norm': 8.443219184875488, 'learning_rate': 0.0008512064343163539, 'epoch': 1.487935656836461}\n",
      "{'loss': 0.3254, 'grad_norm': 5.10312557220459, 'learning_rate': 0.0008498659517426274, 'epoch': 1.5013404825737267}\n",
      "{'loss': 0.3184, 'grad_norm': 1.7099689245224, 'learning_rate': 0.0008485254691689008, 'epoch': 1.5147453083109919}\n",
      "{'loss': 0.3547, 'grad_norm': 14.488799095153809, 'learning_rate': 0.0008471849865951743, 'epoch': 1.5281501340482575}\n",
      "{'loss': 0.3132, 'grad_norm': 6.444786548614502, 'learning_rate': 0.0008458445040214477, 'epoch': 1.5415549597855227}\n",
      "{'loss': 0.2997, 'grad_norm': 6.635915279388428, 'learning_rate': 0.0008445040214477212, 'epoch': 1.5549597855227884}\n",
      "{'loss': 0.3051, 'grad_norm': 13.323573112487793, 'learning_rate': 0.0008431635388739947, 'epoch': 1.5683646112600536}\n",
      "{'loss': 0.3157, 'grad_norm': 10.72839641571045, 'learning_rate': 0.0008418230563002682, 'epoch': 1.5817694369973192}\n",
      "{'loss': 0.3409, 'grad_norm': 15.094630241394043, 'learning_rate': 0.0008404825737265416, 'epoch': 1.5951742627345844}\n",
      "{'loss': 0.3054, 'grad_norm': 5.176419258117676, 'learning_rate': 0.0008391420911528151, 'epoch': 1.6085790884718498}\n",
      "{'loss': 0.3009, 'grad_norm': 4.514197826385498, 'learning_rate': 0.0008378016085790885, 'epoch': 1.6219839142091153}\n",
      "{'loss': 0.3377, 'grad_norm': 13.45694351196289, 'learning_rate': 0.000836461126005362, 'epoch': 1.6353887399463807}\n",
      "{'loss': 0.327, 'grad_norm': 7.438486099243164, 'learning_rate': 0.0008351206434316354, 'epoch': 1.648793565683646}\n",
      "{'loss': 0.3119, 'grad_norm': 2.5944907665252686, 'learning_rate': 0.0008337801608579089, 'epoch': 1.6621983914209115}\n",
      "{'loss': 0.2883, 'grad_norm': 9.7137451171875, 'learning_rate': 0.0008324396782841823, 'epoch': 1.675603217158177}\n",
      "{'loss': 0.2784, 'grad_norm': 15.880454063415527, 'learning_rate': 0.0008310991957104557, 'epoch': 1.6890080428954424}\n",
      "{'loss': 0.3106, 'grad_norm': 1.8921337127685547, 'learning_rate': 0.0008297587131367292, 'epoch': 1.7024128686327078}\n",
      "{'loss': 0.3291, 'grad_norm': 9.712374687194824, 'learning_rate': 0.0008284182305630026, 'epoch': 1.7158176943699732}\n",
      "{'loss': 0.3222, 'grad_norm': 6.658097743988037, 'learning_rate': 0.0008270777479892762, 'epoch': 1.7292225201072386}\n",
      "{'loss': 0.3263, 'grad_norm': 4.266052722930908, 'learning_rate': 0.0008257372654155496, 'epoch': 1.742627345844504}\n",
      "{'loss': 0.3363, 'grad_norm': 17.77420997619629, 'learning_rate': 0.0008243967828418231, 'epoch': 1.7560321715817695}\n",
      "{'loss': 0.3338, 'grad_norm': 9.321340560913086, 'learning_rate': 0.0008230563002680965, 'epoch': 1.7694369973190347}\n",
      "{'loss': 0.3122, 'grad_norm': 14.319988250732422, 'learning_rate': 0.00082171581769437, 'epoch': 1.7828418230563003}\n",
      "{'loss': 0.2984, 'grad_norm': 32.38979721069336, 'learning_rate': 0.0008203753351206434, 'epoch': 1.7962466487935655}\n",
      "{'loss': 0.3092, 'grad_norm': 16.14073371887207, 'learning_rate': 0.0008190348525469169, 'epoch': 1.8096514745308312}\n",
      "{'loss': 0.3203, 'grad_norm': 17.946895599365234, 'learning_rate': 0.0008176943699731903, 'epoch': 1.8230563002680964}\n",
      "{'loss': 0.335, 'grad_norm': 6.089797496795654, 'learning_rate': 0.0008163538873994638, 'epoch': 1.836461126005362}\n",
      "{'loss': 0.3258, 'grad_norm': 2.2553658485412598, 'learning_rate': 0.0008150134048257372, 'epoch': 1.8498659517426272}\n",
      "{'loss': 0.3584, 'grad_norm': 5.733699798583984, 'learning_rate': 0.0008136729222520107, 'epoch': 1.863270777479893}\n",
      "{'loss': 0.317, 'grad_norm': 19.144760131835938, 'learning_rate': 0.0008123324396782842, 'epoch': 1.876675603217158}\n",
      "{'loss': 0.336, 'grad_norm': 19.192771911621094, 'learning_rate': 0.0008109919571045577, 'epoch': 1.8900804289544237}\n",
      "{'loss': 0.3236, 'grad_norm': 16.966920852661133, 'learning_rate': 0.0008096514745308311, 'epoch': 1.903485254691689}\n",
      "{'loss': 0.3369, 'grad_norm': 9.924850463867188, 'learning_rate': 0.0008083109919571046, 'epoch': 1.9168900804289544}\n",
      "{'loss': 0.3483, 'grad_norm': 23.822044372558594, 'learning_rate': 0.000806970509383378, 'epoch': 1.9302949061662198}\n",
      "{'loss': 0.333, 'grad_norm': 5.9650774002075195, 'learning_rate': 0.0008056300268096515, 'epoch': 1.9436997319034852}\n",
      "{'loss': 0.3564, 'grad_norm': 24.701658248901367, 'learning_rate': 0.0008042895442359249, 'epoch': 1.9571045576407506}\n",
      "{'loss': 0.3328, 'grad_norm': 12.708566665649414, 'learning_rate': 0.0008029490616621984, 'epoch': 1.970509383378016}\n",
      "{'loss': 0.3483, 'grad_norm': 3.7853920459747314, 'learning_rate': 0.0008016085790884718, 'epoch': 1.9839142091152815}\n",
      "{'loss': 0.3199, 'grad_norm': 19.338476181030273, 'learning_rate': 0.0008002680965147453, 'epoch': 1.997319034852547}\n",
      "{'eval_loss': 0.339333176612854, 'eval_accuracy': 0.8984375, 'eval_runtime': 5.3516, 'eval_samples_per_second': 119.591, 'eval_steps_per_second': 1.869, 'epoch': 2.0}\n",
      "{'loss': 0.3335, 'grad_norm': 15.650420188903809, 'learning_rate': 0.0007989276139410187, 'epoch': 2.0107238605898123}\n",
      "{'loss': 0.3421, 'grad_norm': 9.371842384338379, 'learning_rate': 0.0007975871313672923, 'epoch': 2.0241286863270775}\n",
      "{'loss': 0.3697, 'grad_norm': 7.446218967437744, 'learning_rate': 0.0007962466487935657, 'epoch': 2.037533512064343}\n",
      "{'loss': 0.3545, 'grad_norm': 5.063420295715332, 'learning_rate': 0.0007949061662198392, 'epoch': 2.0509383378016084}\n",
      "{'loss': 0.351, 'grad_norm': 23.166744232177734, 'learning_rate': 0.0007935656836461126, 'epoch': 2.064343163538874}\n",
      "{'loss': 0.3211, 'grad_norm': 6.3823723793029785, 'learning_rate': 0.0007922252010723861, 'epoch': 2.0777479892761392}\n",
      "{'loss': 0.309, 'grad_norm': 25.223474502563477, 'learning_rate': 0.0007908847184986595, 'epoch': 2.091152815013405}\n",
      "{'loss': 0.3248, 'grad_norm': 10.959451675415039, 'learning_rate': 0.000789544235924933, 'epoch': 2.10455764075067}\n",
      "{'loss': 0.3541, 'grad_norm': 35.67422103881836, 'learning_rate': 0.0007882037533512064, 'epoch': 2.1179624664879357}\n",
      "{'loss': 0.3421, 'grad_norm': 20.29595184326172, 'learning_rate': 0.0007868632707774799, 'epoch': 2.131367292225201}\n",
      "{'loss': 0.3472, 'grad_norm': 9.63974666595459, 'learning_rate': 0.0007855227882037533, 'epoch': 2.1447721179624666}\n",
      "{'loss': 0.3269, 'grad_norm': 8.602927207946777, 'learning_rate': 0.0007841823056300268, 'epoch': 2.158176943699732}\n",
      "{'loss': 0.3107, 'grad_norm': 20.876354217529297, 'learning_rate': 0.0007828418230563002, 'epoch': 2.1715817694369974}\n",
      "{'loss': 0.3496, 'grad_norm': 9.439821243286133, 'learning_rate': 0.0007815013404825738, 'epoch': 2.1849865951742626}\n",
      "{'loss': 0.2925, 'grad_norm': 17.36212158203125, 'learning_rate': 0.0007801608579088472, 'epoch': 2.1983914209115283}\n",
      "{'loss': 0.3685, 'grad_norm': 29.762523651123047, 'learning_rate': 0.0007788203753351207, 'epoch': 2.2117962466487935}\n",
      "{'loss': 0.3329, 'grad_norm': 56.1097526550293, 'learning_rate': 0.0007774798927613941, 'epoch': 2.225201072386059}\n",
      "{'loss': 0.3032, 'grad_norm': 41.34407424926758, 'learning_rate': 0.0007761394101876675, 'epoch': 2.2386058981233243}\n",
      "{'loss': 0.3383, 'grad_norm': 13.630807876586914, 'learning_rate': 0.000774798927613941, 'epoch': 2.25201072386059}\n",
      "{'loss': 0.3455, 'grad_norm': 9.007411003112793, 'learning_rate': 0.0007734584450402144, 'epoch': 2.265415549597855}\n",
      "{'loss': 0.3466, 'grad_norm': 17.2187442779541, 'learning_rate': 0.0007721179624664879, 'epoch': 2.278820375335121}\n",
      "{'loss': 0.3616, 'grad_norm': 20.203060150146484, 'learning_rate': 0.0007707774798927613, 'epoch': 2.292225201072386}\n",
      "{'loss': 0.3442, 'grad_norm': 33.22034454345703, 'learning_rate': 0.0007694369973190348, 'epoch': 2.3056300268096512}\n",
      "{'loss': 0.3169, 'grad_norm': 95.6688232421875, 'learning_rate': 0.0007680965147453082, 'epoch': 2.319034852546917}\n",
      "{'loss': 0.3321, 'grad_norm': 34.36687469482422, 'learning_rate': 0.0007667560321715818, 'epoch': 2.3324396782841825}\n",
      "{'loss': 0.3605, 'grad_norm': 5.556778907775879, 'learning_rate': 0.0007654155495978552, 'epoch': 2.3458445040214477}\n",
      "{'loss': 0.3617, 'grad_norm': 26.502010345458984, 'learning_rate': 0.0007640750670241287, 'epoch': 2.359249329758713}\n",
      "{'loss': 0.3295, 'grad_norm': 23.24473762512207, 'learning_rate': 0.0007627345844504021, 'epoch': 2.3726541554959786}\n",
      "{'loss': 0.3035, 'grad_norm': 18.11130142211914, 'learning_rate': 0.0007613941018766756, 'epoch': 2.386058981233244}\n",
      "{'loss': 0.3464, 'grad_norm': 9.467002868652344, 'learning_rate': 0.000760053619302949, 'epoch': 2.3994638069705094}\n",
      "{'loss': 0.3893, 'grad_norm': 18.609926223754883, 'learning_rate': 0.0007587131367292225, 'epoch': 2.4128686327077746}\n",
      "{'loss': 0.3411, 'grad_norm': 56.105674743652344, 'learning_rate': 0.0007573726541554959, 'epoch': 2.4262734584450403}\n",
      "{'loss': 0.3441, 'grad_norm': 33.225242614746094, 'learning_rate': 0.0007560321715817694, 'epoch': 2.4396782841823055}\n",
      "{'loss': 0.3632, 'grad_norm': 19.146526336669922, 'learning_rate': 0.0007546916890080428, 'epoch': 2.453083109919571}\n",
      "{'loss': 0.3402, 'grad_norm': 20.821516036987305, 'learning_rate': 0.0007533512064343163, 'epoch': 2.4664879356568363}\n",
      "{'loss': 0.3437, 'grad_norm': 18.57223892211914, 'learning_rate': 0.0007520107238605897, 'epoch': 2.479892761394102}\n",
      "{'loss': 0.369, 'grad_norm': 29.14568328857422, 'learning_rate': 0.0007506702412868633, 'epoch': 2.493297587131367}\n",
      "{'loss': 0.3478, 'grad_norm': 44.431495666503906, 'learning_rate': 0.0007493297587131368, 'epoch': 2.506702412868633}\n",
      "{'loss': 0.3342, 'grad_norm': 29.767786026000977, 'learning_rate': 0.0007479892761394103, 'epoch': 2.520107238605898}\n",
      "{'loss': 0.3424, 'grad_norm': 36.91706466674805, 'learning_rate': 0.0007466487935656837, 'epoch': 2.5335120643431637}\n",
      "{'loss': 0.3526, 'grad_norm': 32.810699462890625, 'learning_rate': 0.0007453083109919572, 'epoch': 2.546916890080429}\n",
      "{'loss': 0.3556, 'grad_norm': 6.018138885498047, 'learning_rate': 0.0007439678284182306, 'epoch': 2.5603217158176945}\n",
      "{'loss': 0.3712, 'grad_norm': 25.28091049194336, 'learning_rate': 0.0007426273458445041, 'epoch': 2.5737265415549597}\n",
      "{'loss': 0.3276, 'grad_norm': 27.44465446472168, 'learning_rate': 0.0007412868632707775, 'epoch': 2.5871313672922254}\n",
      "{'loss': 0.3928, 'grad_norm': 41.83715057373047, 'learning_rate': 0.000739946380697051, 'epoch': 2.6005361930294906}\n",
      "{'loss': 0.3501, 'grad_norm': 15.534351348876953, 'learning_rate': 0.0007386058981233244, 'epoch': 2.6139410187667558}\n",
      "{'loss': 0.384, 'grad_norm': 16.49209976196289, 'learning_rate': 0.000737265415549598, 'epoch': 2.6273458445040214}\n",
      "{'loss': 0.3866, 'grad_norm': 19.82813262939453, 'learning_rate': 0.0007359249329758714, 'epoch': 2.640750670241287}\n",
      "{'loss': 0.3698, 'grad_norm': 14.363165855407715, 'learning_rate': 0.0007345844504021449, 'epoch': 2.6541554959785523}\n",
      "{'loss': 0.3669, 'grad_norm': 27.430646896362305, 'learning_rate': 0.0007332439678284183, 'epoch': 2.6675603217158175}\n",
      "{'loss': 0.3563, 'grad_norm': 29.611448287963867, 'learning_rate': 0.0007319034852546918, 'epoch': 2.680965147453083}\n",
      "{'loss': 0.3746, 'grad_norm': 25.33013153076172, 'learning_rate': 0.0007305630026809652, 'epoch': 2.6943699731903488}\n",
      "{'loss': 0.3717, 'grad_norm': 66.5324478149414, 'learning_rate': 0.0007292225201072387, 'epoch': 2.707774798927614}\n",
      "{'loss': 0.3467, 'grad_norm': 21.64008331298828, 'learning_rate': 0.0007278820375335121, 'epoch': 2.721179624664879}\n",
      "{'loss': 0.3385, 'grad_norm': 17.32952880859375, 'learning_rate': 0.0007265415549597856, 'epoch': 2.734584450402145}\n",
      "{'loss': 0.3825, 'grad_norm': 62.70297622680664, 'learning_rate': 0.000725201072386059, 'epoch': 2.7479892761394105}\n",
      "{'loss': 0.3503, 'grad_norm': 15.913406372070312, 'learning_rate': 0.0007238605898123325, 'epoch': 2.7613941018766757}\n",
      "{'loss': 0.4164, 'grad_norm': 20.055267333984375, 'learning_rate': 0.000722520107238606, 'epoch': 2.774798927613941}\n",
      "{'loss': 0.3581, 'grad_norm': 23.248760223388672, 'learning_rate': 0.0007211796246648794, 'epoch': 2.7882037533512065}\n",
      "{'loss': 0.3858, 'grad_norm': 20.38987922668457, 'learning_rate': 0.0007198391420911529, 'epoch': 2.8016085790884717}\n",
      "{'loss': 0.3835, 'grad_norm': 39.89190673828125, 'learning_rate': 0.0007184986595174263, 'epoch': 2.8150134048257374}\n",
      "{'loss': 0.3642, 'grad_norm': 16.89485740661621, 'learning_rate': 0.0007171581769436998, 'epoch': 2.8284182305630026}\n",
      "{'loss': 0.396, 'grad_norm': 15.24336051940918, 'learning_rate': 0.0007158176943699732, 'epoch': 2.841823056300268}\n",
      "{'loss': 0.3344, 'grad_norm': 8.974599838256836, 'learning_rate': 0.0007144772117962467, 'epoch': 2.8552278820375334}\n",
      "{'loss': 0.4022, 'grad_norm': 90.0494384765625, 'learning_rate': 0.0007131367292225201, 'epoch': 2.868632707774799}\n",
      "{'loss': 0.3413, 'grad_norm': 51.715904235839844, 'learning_rate': 0.0007117962466487936, 'epoch': 2.8820375335120643}\n",
      "{'loss': 0.3603, 'grad_norm': 27.650617599487305, 'learning_rate': 0.000710455764075067, 'epoch': 2.89544235924933}\n",
      "{'loss': 0.3444, 'grad_norm': 19.745412826538086, 'learning_rate': 0.0007091152815013405, 'epoch': 2.908847184986595}\n",
      "{'loss': 0.3619, 'grad_norm': 8.500750541687012, 'learning_rate': 0.0007077747989276139, 'epoch': 2.9222520107238603}\n",
      "{'loss': 0.3807, 'grad_norm': 13.149924278259277, 'learning_rate': 0.0007064343163538875, 'epoch': 2.935656836461126}\n",
      "{'loss': 0.3552, 'grad_norm': 32.94142532348633, 'learning_rate': 0.0007050938337801609, 'epoch': 2.9490616621983916}\n",
      "{'loss': 0.3226, 'grad_norm': 13.623678207397461, 'learning_rate': 0.0007037533512064344, 'epoch': 2.962466487935657}\n",
      "{'loss': 0.3557, 'grad_norm': 22.784109115600586, 'learning_rate': 0.0007024128686327078, 'epoch': 2.975871313672922}\n",
      "{'loss': 0.3687, 'grad_norm': 36.82371139526367, 'learning_rate': 0.0007010723860589813, 'epoch': 2.9892761394101877}\n",
      "{'eval_loss': 0.32795557379722595, 'eval_accuracy': 0.890625, 'eval_runtime': 5.3346, 'eval_samples_per_second': 119.971, 'eval_steps_per_second': 1.875, 'epoch': 3.0}\n",
      "{'loss': 0.3356, 'grad_norm': 27.504257202148438, 'learning_rate': 0.0006997319034852547, 'epoch': 3.002680965147453}\n",
      "{'loss': 0.3542, 'grad_norm': 92.18180847167969, 'learning_rate': 0.0006983914209115282, 'epoch': 3.0160857908847185}\n",
      "{'loss': 0.3436, 'grad_norm': 45.569793701171875, 'learning_rate': 0.0006970509383378016, 'epoch': 3.0294906166219837}\n",
      "{'loss': 0.3579, 'grad_norm': 16.228437423706055, 'learning_rate': 0.0006957104557640751, 'epoch': 3.0428954423592494}\n",
      "{'loss': 0.43, 'grad_norm': 71.12030792236328, 'learning_rate': 0.0006943699731903485, 'epoch': 3.0563002680965146}\n",
      "{'loss': 0.331, 'grad_norm': 36.91561508178711, 'learning_rate': 0.000693029490616622, 'epoch': 3.06970509383378}\n",
      "{'loss': 0.3581, 'grad_norm': 28.705881118774414, 'learning_rate': 0.0006916890080428954, 'epoch': 3.0831099195710454}\n",
      "{'loss': 0.352, 'grad_norm': 41.835304260253906, 'learning_rate': 0.000690348525469169, 'epoch': 3.096514745308311}\n",
      "{'loss': 0.3754, 'grad_norm': 19.829753875732422, 'learning_rate': 0.0006890080428954424, 'epoch': 3.1099195710455763}\n",
      "{'loss': 0.4409, 'grad_norm': 51.66005325317383, 'learning_rate': 0.0006876675603217159, 'epoch': 3.123324396782842}\n",
      "{'loss': 0.3703, 'grad_norm': 24.606552124023438, 'learning_rate': 0.0006863270777479893, 'epoch': 3.136729222520107}\n",
      "{'loss': 0.3662, 'grad_norm': 20.52979278564453, 'learning_rate': 0.0006849865951742628, 'epoch': 3.1501340482573728}\n",
      "{'loss': 0.3881, 'grad_norm': 39.821292877197266, 'learning_rate': 0.0006836461126005362, 'epoch': 3.163538873994638}\n",
      "{'loss': 0.3935, 'grad_norm': 37.083282470703125, 'learning_rate': 0.0006823056300268097, 'epoch': 3.1769436997319036}\n",
      "{'loss': 0.378, 'grad_norm': 32.73958206176758, 'learning_rate': 0.0006809651474530831, 'epoch': 3.190348525469169}\n",
      "{'loss': 0.362, 'grad_norm': 18.20214080810547, 'learning_rate': 0.0006796246648793566, 'epoch': 3.2037533512064345}\n",
      "{'loss': 0.4089, 'grad_norm': 43.88423156738281, 'learning_rate': 0.00067828418230563, 'epoch': 3.2171581769436997}\n",
      "{'loss': 0.3748, 'grad_norm': 40.56355285644531, 'learning_rate': 0.0006769436997319036, 'epoch': 3.2305630026809653}\n",
      "{'loss': 0.3693, 'grad_norm': 24.682968139648438, 'learning_rate': 0.000675603217158177, 'epoch': 3.2439678284182305}\n",
      "{'loss': 0.3977, 'grad_norm': 12.185976028442383, 'learning_rate': 0.0006742627345844505, 'epoch': 3.257372654155496}\n",
      "{'loss': 0.3534, 'grad_norm': 104.2469253540039, 'learning_rate': 0.0006729222520107239, 'epoch': 3.2707774798927614}\n",
      "{'loss': 0.395, 'grad_norm': 15.744260787963867, 'learning_rate': 0.0006715817694369974, 'epoch': 3.284182305630027}\n",
      "{'loss': 0.3901, 'grad_norm': 18.75100326538086, 'learning_rate': 0.0006702412868632708, 'epoch': 3.297587131367292}\n",
      "{'loss': 0.3774, 'grad_norm': 24.120105743408203, 'learning_rate': 0.0006689008042895443, 'epoch': 3.310991957104558}\n",
      "{'loss': 0.3741, 'grad_norm': 40.47783660888672, 'learning_rate': 0.0006675603217158177, 'epoch': 3.324396782841823}\n",
      "{'loss': 0.3645, 'grad_norm': 60.58961486816406, 'learning_rate': 0.0006662198391420911, 'epoch': 3.3378016085790883}\n",
      "{'loss': 0.4005, 'grad_norm': 78.62262725830078, 'learning_rate': 0.0006648793565683646, 'epoch': 3.351206434316354}\n",
      "{'loss': 0.3551, 'grad_norm': 24.14847755432129, 'learning_rate': 0.000663538873994638, 'epoch': 3.3646112600536195}\n",
      "{'loss': 0.3386, 'grad_norm': 80.12457275390625, 'learning_rate': 0.0006621983914209115, 'epoch': 3.3780160857908847}\n",
      "{'loss': 0.3717, 'grad_norm': 46.5128288269043, 'learning_rate': 0.000660857908847185, 'epoch': 3.39142091152815}\n",
      "{'loss': 0.3439, 'grad_norm': 100.89350128173828, 'learning_rate': 0.0006595174262734585, 'epoch': 3.4048257372654156}\n",
      "{'loss': 0.3408, 'grad_norm': 53.52426528930664, 'learning_rate': 0.0006581769436997319, 'epoch': 3.418230563002681}\n",
      "{'loss': 0.3485, 'grad_norm': 613.2277221679688, 'learning_rate': 0.0006568364611260054, 'epoch': 3.4316353887399464}\n",
      "{'loss': 0.352, 'grad_norm': 3.5539638996124268, 'learning_rate': 0.0006554959785522788, 'epoch': 3.4450402144772116}\n",
      "{'loss': 0.3688, 'grad_norm': 19.007648468017578, 'learning_rate': 0.0006541554959785523, 'epoch': 3.4584450402144773}\n",
      "{'loss': 0.3795, 'grad_norm': 24.724681854248047, 'learning_rate': 0.0006528150134048257, 'epoch': 3.4718498659517425}\n",
      "{'loss': 0.3601, 'grad_norm': 35.60210418701172, 'learning_rate': 0.0006514745308310992, 'epoch': 3.485254691689008}\n",
      "{'loss': 0.3526, 'grad_norm': 12.220114707946777, 'learning_rate': 0.0006501340482573726, 'epoch': 3.4986595174262733}\n",
      "{'loss': 0.3666, 'grad_norm': 50.88587951660156, 'learning_rate': 0.0006487935656836461, 'epoch': 3.512064343163539}\n",
      "{'loss': 0.3831, 'grad_norm': 58.667545318603516, 'learning_rate': 0.0006474530831099195, 'epoch': 3.525469168900804}\n",
      "{'loss': 0.3444, 'grad_norm': 77.65904235839844, 'learning_rate': 0.000646112600536193, 'epoch': 3.53887399463807}\n",
      "{'loss': 0.3767, 'grad_norm': 36.757667541503906, 'learning_rate': 0.0006447721179624665, 'epoch': 3.552278820375335}\n",
      "{'loss': 0.3507, 'grad_norm': 26.849746704101562, 'learning_rate': 0.00064343163538874, 'epoch': 3.5656836461126007}\n",
      "{'loss': 0.3498, 'grad_norm': 41.10587692260742, 'learning_rate': 0.0006420911528150134, 'epoch': 3.579088471849866}\n",
      "{'loss': 0.3637, 'grad_norm': 102.17613983154297, 'learning_rate': 0.0006407506702412869, 'epoch': 3.592493297587131}\n",
      "{'loss': 0.3096, 'grad_norm': 25.328126907348633, 'learning_rate': 0.0006394101876675603, 'epoch': 3.6058981233243967}\n",
      "{'loss': 0.3746, 'grad_norm': 43.68791198730469, 'learning_rate': 0.0006380697050938338, 'epoch': 3.6193029490616624}\n",
      "{'loss': 0.3571, 'grad_norm': 65.5145034790039, 'learning_rate': 0.0006367292225201072, 'epoch': 3.6327077747989276}\n",
      "{'loss': 0.3816, 'grad_norm': 22.18691635131836, 'learning_rate': 0.0006353887399463807, 'epoch': 3.646112600536193}\n",
      "{'loss': 0.35, 'grad_norm': 27.758590698242188, 'learning_rate': 0.0006340482573726541, 'epoch': 3.6595174262734584}\n",
      "{'loss': 0.3714, 'grad_norm': 31.887248992919922, 'learning_rate': 0.0006327077747989276, 'epoch': 3.672922252010724}\n",
      "{'loss': 0.3853, 'grad_norm': 34.98289108276367, 'learning_rate': 0.000631367292225201, 'epoch': 3.6863270777479893}\n",
      "{'loss': 0.3431, 'grad_norm': 29.881254196166992, 'learning_rate': 0.0006300268096514746, 'epoch': 3.6997319034852545}\n",
      "{'loss': 0.3974, 'grad_norm': 29.675138473510742, 'learning_rate': 0.000628686327077748, 'epoch': 3.71313672922252}\n",
      "{'loss': 0.3256, 'grad_norm': 37.38863754272461, 'learning_rate': 0.0006273458445040215, 'epoch': 3.726541554959786}\n",
      "{'loss': 0.3513, 'grad_norm': 16.128488540649414, 'learning_rate': 0.0006260053619302949, 'epoch': 3.739946380697051}\n",
      "{'loss': 0.3852, 'grad_norm': 52.23573684692383, 'learning_rate': 0.0006246648793565684, 'epoch': 3.753351206434316}\n",
      "{'loss': 0.3704, 'grad_norm': 35.019256591796875, 'learning_rate': 0.0006233243967828418, 'epoch': 3.766756032171582}\n",
      "{'loss': 0.3902, 'grad_norm': 21.583898544311523, 'learning_rate': 0.0006219839142091153, 'epoch': 3.780160857908847}\n",
      "{'loss': 0.3849, 'grad_norm': 75.97234344482422, 'learning_rate': 0.0006206434316353887, 'epoch': 3.7935656836461127}\n",
      "{'loss': 0.3833, 'grad_norm': 45.83179473876953, 'learning_rate': 0.0006193029490616622, 'epoch': 3.806970509383378}\n",
      "{'loss': 0.4031, 'grad_norm': 38.803993225097656, 'learning_rate': 0.0006179624664879356, 'epoch': 3.8203753351206435}\n",
      "{'loss': 0.3963, 'grad_norm': 10.662697792053223, 'learning_rate': 0.0006166219839142091, 'epoch': 3.8337801608579087}\n",
      "{'loss': 0.4001, 'grad_norm': 25.432723999023438, 'learning_rate': 0.0006152815013404825, 'epoch': 3.8471849865951744}\n",
      "{'loss': 0.3927, 'grad_norm': 15.525811195373535, 'learning_rate': 0.0006139410187667561, 'epoch': 3.8605898123324396}\n",
      "{'loss': 0.4148, 'grad_norm': 30.14438247680664, 'learning_rate': 0.0006126005361930295, 'epoch': 3.8739946380697052}\n",
      "{'loss': 0.3975, 'grad_norm': 35.46578598022461, 'learning_rate': 0.0006112600536193029, 'epoch': 3.8873994638069704}\n",
      "{'loss': 0.4247, 'grad_norm': 30.891199111938477, 'learning_rate': 0.0006099195710455764, 'epoch': 3.900804289544236}\n",
      "{'loss': 0.3822, 'grad_norm': 37.61762619018555, 'learning_rate': 0.0006085790884718498, 'epoch': 3.9142091152815013}\n",
      "{'loss': 0.3842, 'grad_norm': 31.836755752563477, 'learning_rate': 0.0006072386058981233, 'epoch': 3.927613941018767}\n",
      "{'loss': 0.368, 'grad_norm': 14.800092697143555, 'learning_rate': 0.0006058981233243967, 'epoch': 3.941018766756032}\n",
      "{'loss': 0.4086, 'grad_norm': 24.609373092651367, 'learning_rate': 0.0006045576407506702, 'epoch': 3.9544235924932973}\n",
      "{'loss': 0.3834, 'grad_norm': 22.25054931640625, 'learning_rate': 0.0006032171581769436, 'epoch': 3.967828418230563}\n",
      "{'loss': 0.3573, 'grad_norm': 9.334500312805176, 'learning_rate': 0.0006018766756032171, 'epoch': 3.9812332439678286}\n",
      "{'loss': 0.3727, 'grad_norm': 26.263145446777344, 'learning_rate': 0.0006005361930294905, 'epoch': 3.994638069705094}\n",
      "{'eval_loss': 0.3418242633342743, 'eval_accuracy': 0.8953125, 'eval_runtime': 5.3162, 'eval_samples_per_second': 120.387, 'eval_steps_per_second': 1.881, 'epoch': 4.0}\n",
      "{'loss': 0.371, 'grad_norm': 21.609954833984375, 'learning_rate': 0.0005991957104557641, 'epoch': 4.008042895442359}\n",
      "{'loss': 0.3619, 'grad_norm': 18.443313598632812, 'learning_rate': 0.0005978552278820375, 'epoch': 4.021447721179625}\n",
      "{'loss': 0.3986, 'grad_norm': 28.24334144592285, 'learning_rate': 0.000596514745308311, 'epoch': 4.03485254691689}\n",
      "{'loss': 0.3533, 'grad_norm': 51.485294342041016, 'learning_rate': 0.0005951742627345844, 'epoch': 4.048257372654155}\n",
      "{'loss': 0.3456, 'grad_norm': 11.101137161254883, 'learning_rate': 0.0005938337801608579, 'epoch': 4.061662198391421}\n",
      "{'loss': 0.3439, 'grad_norm': 24.074687957763672, 'learning_rate': 0.0005924932975871313, 'epoch': 4.075067024128686}\n",
      "{'loss': 0.3377, 'grad_norm': 25.87359619140625, 'learning_rate': 0.0005911528150134048, 'epoch': 4.088471849865952}\n",
      "{'loss': 0.3482, 'grad_norm': 10.00726318359375, 'learning_rate': 0.0005898123324396782, 'epoch': 4.101876675603217}\n",
      "{'loss': 0.3293, 'grad_norm': 8.766416549682617, 'learning_rate': 0.0005884718498659517, 'epoch': 4.115281501340482}\n",
      "{'loss': 0.3485, 'grad_norm': 20.32184410095215, 'learning_rate': 0.0005871313672922251, 'epoch': 4.128686327077748}\n",
      "{'loss': 0.3423, 'grad_norm': 9.210122108459473, 'learning_rate': 0.0005857908847184986, 'epoch': 4.142091152815014}\n",
      "{'loss': 0.3748, 'grad_norm': 20.66933250427246, 'learning_rate': 0.000584450402144772, 'epoch': 4.1554959785522785}\n",
      "{'loss': 0.3568, 'grad_norm': 9.923103332519531, 'learning_rate': 0.0005831099195710457, 'epoch': 4.168900804289544}\n",
      "{'loss': 0.3596, 'grad_norm': 11.87820053100586, 'learning_rate': 0.0005817694369973191, 'epoch': 4.18230563002681}\n",
      "{'loss': 0.3827, 'grad_norm': 19.04463005065918, 'learning_rate': 0.0005804289544235926, 'epoch': 4.195710455764075}\n",
      "{'loss': 0.385, 'grad_norm': 14.140396118164062, 'learning_rate': 0.000579088471849866, 'epoch': 4.20911528150134}\n",
      "{'loss': 0.4026, 'grad_norm': 32.418540954589844, 'learning_rate': 0.0005777479892761395, 'epoch': 4.222520107238606}\n",
      "{'loss': 0.3748, 'grad_norm': 25.1518611907959, 'learning_rate': 0.0005764075067024129, 'epoch': 4.2359249329758715}\n",
      "{'loss': 0.3624, 'grad_norm': 24.107215881347656, 'learning_rate': 0.0005750670241286864, 'epoch': 4.249329758713137}\n",
      "{'loss': 0.3364, 'grad_norm': 36.77047348022461, 'learning_rate': 0.0005737265415549598, 'epoch': 4.262734584450402}\n",
      "{'loss': 0.3535, 'grad_norm': 37.21217346191406, 'learning_rate': 0.0005723860589812333, 'epoch': 4.2761394101876675}\n",
      "{'loss': 0.3682, 'grad_norm': 31.759143829345703, 'learning_rate': 0.0005710455764075067, 'epoch': 4.289544235924933}\n",
      "{'loss': 0.3667, 'grad_norm': 26.451168060302734, 'learning_rate': 0.0005697050938337803, 'epoch': 4.302949061662199}\n",
      "{'loss': 0.3271, 'grad_norm': 47.5980224609375, 'learning_rate': 0.0005683646112600537, 'epoch': 4.316353887399464}\n",
      "{'loss': 0.3509, 'grad_norm': 17.535911560058594, 'learning_rate': 0.0005670241286863272, 'epoch': 4.329758713136729}\n",
      "{'loss': 0.337, 'grad_norm': 21.424976348876953, 'learning_rate': 0.0005656836461126006, 'epoch': 4.343163538873995}\n",
      "{'loss': 0.3796, 'grad_norm': 28.259260177612305, 'learning_rate': 0.0005643431635388741, 'epoch': 4.35656836461126}\n",
      "{'loss': 0.3751, 'grad_norm': 23.727516174316406, 'learning_rate': 0.0005630026809651475, 'epoch': 4.369973190348525}\n",
      "{'loss': 0.3629, 'grad_norm': 33.97636413574219, 'learning_rate': 0.000561662198391421, 'epoch': 4.383378016085791}\n",
      "{'loss': 0.3699, 'grad_norm': 22.528898239135742, 'learning_rate': 0.0005603217158176944, 'epoch': 4.396782841823057}\n",
      "{'loss': 0.3798, 'grad_norm': 43.331947326660156, 'learning_rate': 0.0005589812332439679, 'epoch': 4.410187667560321}\n",
      "{'loss': 0.3159, 'grad_norm': 12.91252326965332, 'learning_rate': 0.0005576407506702413, 'epoch': 4.423592493297587}\n",
      "{'loss': 0.3598, 'grad_norm': 11.00381088256836, 'learning_rate': 0.0005563002680965148, 'epoch': 4.436997319034853}\n",
      "{'loss': 0.3062, 'grad_norm': 21.97848892211914, 'learning_rate': 0.0005549597855227883, 'epoch': 4.450402144772118}\n",
      "{'loss': 0.3442, 'grad_norm': 18.797409057617188, 'learning_rate': 0.0005536193029490617, 'epoch': 4.463806970509383}\n",
      "{'loss': 0.3641, 'grad_norm': 17.63067054748535, 'learning_rate': 0.0005522788203753352, 'epoch': 4.477211796246649}\n",
      "{'loss': 0.3714, 'grad_norm': 42.799625396728516, 'learning_rate': 0.0005509383378016086, 'epoch': 4.490616621983914}\n",
      "{'loss': 0.3425, 'grad_norm': 18.033145904541016, 'learning_rate': 0.0005495978552278821, 'epoch': 4.50402144772118}\n",
      "{'loss': 0.3675, 'grad_norm': 4.722753524780273, 'learning_rate': 0.0005482573726541555, 'epoch': 4.517426273458445}\n",
      "{'loss': 0.32, 'grad_norm': 9.963927268981934, 'learning_rate': 0.000546916890080429, 'epoch': 4.53083109919571}\n",
      "{'loss': 0.3217, 'grad_norm': 12.2742919921875, 'learning_rate': 0.0005455764075067024, 'epoch': 4.544235924932976}\n",
      "{'loss': 0.3464, 'grad_norm': 18.8590030670166, 'learning_rate': 0.0005442359249329759, 'epoch': 4.557640750670242}\n",
      "{'loss': 0.3383, 'grad_norm': 28.752971649169922, 'learning_rate': 0.0005428954423592493, 'epoch': 4.571045576407506}\n",
      "{'loss': 0.3132, 'grad_norm': 9.46458625793457, 'learning_rate': 0.0005415549597855228, 'epoch': 4.584450402144772}\n",
      "{'loss': 0.3824, 'grad_norm': 29.83346939086914, 'learning_rate': 0.0005402144772117962, 'epoch': 4.597855227882038}\n",
      "{'loss': 0.3143, 'grad_norm': 23.587656021118164, 'learning_rate': 0.0005388739946380698, 'epoch': 4.6112600536193025}\n",
      "{'loss': 0.3637, 'grad_norm': 7.503607273101807, 'learning_rate': 0.0005375335120643432, 'epoch': 4.624664879356568}\n",
      "{'loss': 0.3479, 'grad_norm': 12.089510917663574, 'learning_rate': 0.0005361930294906167, 'epoch': 4.638069705093834}\n",
      "{'loss': 0.3512, 'grad_norm': 27.40380859375, 'learning_rate': 0.0005348525469168901, 'epoch': 4.651474530831099}\n",
      "{'loss': 0.3597, 'grad_norm': 35.17745590209961, 'learning_rate': 0.0005335120643431636, 'epoch': 4.664879356568365}\n",
      "{'loss': 0.3892, 'grad_norm': 158.2747802734375, 'learning_rate': 0.000532171581769437, 'epoch': 4.67828418230563}\n",
      "{'loss': 0.3481, 'grad_norm': 24.215463638305664, 'learning_rate': 0.0005308310991957105, 'epoch': 4.6916890080428955}\n",
      "{'loss': 0.323, 'grad_norm': 4.048189163208008, 'learning_rate': 0.0005294906166219839, 'epoch': 4.705093833780161}\n",
      "{'loss': 0.3733, 'grad_norm': 34.28798294067383, 'learning_rate': 0.0005281501340482574, 'epoch': 4.718498659517426}\n",
      "{'loss': 0.3593, 'grad_norm': 9.757977485656738, 'learning_rate': 0.0005268096514745308, 'epoch': 4.7319034852546915}\n",
      "{'loss': 0.3289, 'grad_norm': 16.138404846191406, 'learning_rate': 0.0005254691689008043, 'epoch': 4.745308310991957}\n",
      "{'loss': 0.348, 'grad_norm': 3.580690622329712, 'learning_rate': 0.0005241286863270778, 'epoch': 4.758713136729223}\n",
      "{'loss': 0.3502, 'grad_norm': 35.53036880493164, 'learning_rate': 0.0005227882037533513, 'epoch': 4.772117962466488}\n",
      "{'loss': 0.3267, 'grad_norm': 33.79093551635742, 'learning_rate': 0.0005214477211796247, 'epoch': 4.785522788203753}\n",
      "{'loss': 0.3323, 'grad_norm': 20.081449508666992, 'learning_rate': 0.0005201072386058982, 'epoch': 4.798927613941019}\n",
      "{'loss': 0.3602, 'grad_norm': 37.12934875488281, 'learning_rate': 0.0005187667560321716, 'epoch': 4.8123324396782845}\n",
      "{'loss': 0.3595, 'grad_norm': 47.34329605102539, 'learning_rate': 0.0005174262734584451, 'epoch': 4.825737265415549}\n",
      "{'loss': 0.3546, 'grad_norm': 12.276809692382812, 'learning_rate': 0.0005160857908847185, 'epoch': 4.839142091152815}\n",
      "{'loss': 0.3473, 'grad_norm': 14.939326286315918, 'learning_rate': 0.000514745308310992, 'epoch': 4.8525469168900806}\n",
      "{'loss': 0.36, 'grad_norm': 13.590975761413574, 'learning_rate': 0.0005134048257372654, 'epoch': 4.865951742627346}\n",
      "{'loss': 0.369, 'grad_norm': 29.68025016784668, 'learning_rate': 0.0005120643431635389, 'epoch': 4.879356568364611}\n",
      "{'loss': 0.3153, 'grad_norm': 3.5076212882995605, 'learning_rate': 0.0005107238605898123, 'epoch': 4.892761394101877}\n",
      "{'loss': 0.325, 'grad_norm': 18.293434143066406, 'learning_rate': 0.0005093833780160859, 'epoch': 4.906166219839142}\n",
      "{'loss': 0.3553, 'grad_norm': 6.201890468597412, 'learning_rate': 0.0005080428954423593, 'epoch': 4.919571045576408}\n",
      "{'loss': 0.3398, 'grad_norm': 34.97114944458008, 'learning_rate': 0.0005067024128686328, 'epoch': 4.932975871313673}\n",
      "{'loss': 0.3307, 'grad_norm': 3.0325214862823486, 'learning_rate': 0.0005053619302949062, 'epoch': 4.946380697050938}\n",
      "{'loss': 0.33, 'grad_norm': 25.22968864440918, 'learning_rate': 0.0005040214477211797, 'epoch': 4.959785522788204}\n",
      "{'loss': 0.3404, 'grad_norm': 14.525533676147461, 'learning_rate': 0.0005026809651474531, 'epoch': 4.973190348525469}\n",
      "{'loss': 0.3718, 'grad_norm': 11.025522232055664, 'learning_rate': 0.0005013404825737266, 'epoch': 4.986595174262734}\n",
      "{'loss': 0.356, 'grad_norm': 5.926759719848633, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'eval_loss': 0.30275124311447144, 'eval_accuracy': 0.9109375, 'eval_runtime': 5.3857, 'eval_samples_per_second': 118.833, 'eval_steps_per_second': 1.857, 'epoch': 5.0}\n",
      "{'loss': 0.3325, 'grad_norm': 12.084771156311035, 'learning_rate': 0.0004986595174262734, 'epoch': 5.013404825737266}\n",
      "{'loss': 0.3447, 'grad_norm': 18.83367347717285, 'learning_rate': 0.0004973190348525469, 'epoch': 5.02680965147453}\n",
      "{'loss': 0.327, 'grad_norm': 48.65313720703125, 'learning_rate': 0.0004959785522788203, 'epoch': 5.040214477211796}\n",
      "{'loss': 0.3313, 'grad_norm': 33.01480484008789, 'learning_rate': 0.0004946380697050938, 'epoch': 5.053619302949062}\n",
      "{'loss': 0.3177, 'grad_norm': 28.30600357055664, 'learning_rate': 0.0004932975871313673, 'epoch': 5.067024128686327}\n",
      "{'loss': 0.3214, 'grad_norm': 10.677928924560547, 'learning_rate': 0.0004919571045576408, 'epoch': 5.080428954423592}\n",
      "{'loss': 0.3264, 'grad_norm': 51.82782745361328, 'learning_rate': 0.0004906166219839142, 'epoch': 5.093833780160858}\n",
      "{'loss': 0.3239, 'grad_norm': 23.977643966674805, 'learning_rate': 0.0004892761394101877, 'epoch': 5.107238605898123}\n",
      "{'loss': 0.3493, 'grad_norm': 64.34943389892578, 'learning_rate': 0.00048793565683646114, 'epoch': 5.120643431635389}\n",
      "{'loss': 0.2901, 'grad_norm': 78.15438079833984, 'learning_rate': 0.0004865951742627346, 'epoch': 5.134048257372654}\n",
      "{'loss': 0.3125, 'grad_norm': 13.49444580078125, 'learning_rate': 0.00048525469168900806, 'epoch': 5.1474530831099194}\n",
      "{'loss': 0.3856, 'grad_norm': 21.11294937133789, 'learning_rate': 0.0004839142091152815, 'epoch': 5.160857908847185}\n",
      "{'loss': 0.3137, 'grad_norm': 12.497762680053711, 'learning_rate': 0.000482573726541555, 'epoch': 5.174262734584451}\n",
      "{'loss': 0.3541, 'grad_norm': 15.433731079101562, 'learning_rate': 0.00048123324396782843, 'epoch': 5.1876675603217155}\n",
      "{'loss': 0.3887, 'grad_norm': 10.981584548950195, 'learning_rate': 0.0004798927613941019, 'epoch': 5.201072386058981}\n",
      "{'loss': 0.3541, 'grad_norm': 16.53544807434082, 'learning_rate': 0.00047855227882037535, 'epoch': 5.214477211796247}\n",
      "{'loss': 0.3577, 'grad_norm': 12.739603996276855, 'learning_rate': 0.0004772117962466488, 'epoch': 5.227882037533512}\n",
      "{'loss': 0.2889, 'grad_norm': 30.065277099609375, 'learning_rate': 0.00047587131367292227, 'epoch': 5.241286863270777}\n",
      "{'loss': 0.3505, 'grad_norm': 2.1964213848114014, 'learning_rate': 0.00047453083109919573, 'epoch': 5.254691689008043}\n",
      "{'loss': 0.3221, 'grad_norm': 28.480947494506836, 'learning_rate': 0.0004731903485254692, 'epoch': 5.2680965147453085}\n",
      "{'loss': 0.3194, 'grad_norm': 26.585702896118164, 'learning_rate': 0.0004718498659517426, 'epoch': 5.281501340482574}\n",
      "{'loss': 0.3454, 'grad_norm': 19.966604232788086, 'learning_rate': 0.00047050938337801605, 'epoch': 5.294906166219839}\n",
      "{'loss': 0.3197, 'grad_norm': 18.104951858520508, 'learning_rate': 0.0004691689008042895, 'epoch': 5.3083109919571045}\n",
      "{'loss': 0.3475, 'grad_norm': 17.26558494567871, 'learning_rate': 0.00046782841823056297, 'epoch': 5.32171581769437}\n",
      "{'loss': 0.3263, 'grad_norm': 34.58720397949219, 'learning_rate': 0.00046648793565683643, 'epoch': 5.335120643431635}\n",
      "{'loss': 0.3833, 'grad_norm': 18.453004837036133, 'learning_rate': 0.0004651474530831099, 'epoch': 5.348525469168901}\n",
      "{'loss': 0.3503, 'grad_norm': 24.577011108398438, 'learning_rate': 0.00046380697050938335, 'epoch': 5.361930294906166}\n",
      "{'loss': 0.3192, 'grad_norm': 36.1280632019043, 'learning_rate': 0.0004624664879356568, 'epoch': 5.375335120643432}\n",
      "{'loss': 0.3338, 'grad_norm': 32.008323669433594, 'learning_rate': 0.00046112600536193026, 'epoch': 5.388739946380697}\n",
      "{'loss': 0.3361, 'grad_norm': 23.03115463256836, 'learning_rate': 0.0004597855227882037, 'epoch': 5.402144772117962}\n",
      "{'loss': 0.3375, 'grad_norm': 7.643578052520752, 'learning_rate': 0.0004584450402144772, 'epoch': 5.415549597855228}\n",
      "{'loss': 0.3494, 'grad_norm': 42.18135452270508, 'learning_rate': 0.0004571045576407507, 'epoch': 5.428954423592494}\n",
      "{'loss': 0.3267, 'grad_norm': 9.911478042602539, 'learning_rate': 0.00045576407506702415, 'epoch': 5.442359249329758}\n",
      "{'loss': 0.3213, 'grad_norm': 12.79383373260498, 'learning_rate': 0.0004544235924932976, 'epoch': 5.455764075067024}\n",
      "{'loss': 0.3259, 'grad_norm': 25.147441864013672, 'learning_rate': 0.00045308310991957107, 'epoch': 5.46916890080429}\n",
      "{'loss': 0.3705, 'grad_norm': 13.104863166809082, 'learning_rate': 0.00045174262734584453, 'epoch': 5.482573726541555}\n",
      "{'loss': 0.3239, 'grad_norm': 54.258392333984375, 'learning_rate': 0.000450402144772118, 'epoch': 5.49597855227882}\n",
      "{'loss': 0.3638, 'grad_norm': 15.709746360778809, 'learning_rate': 0.00044906166219839145, 'epoch': 5.509383378016086}\n",
      "{'loss': 0.3851, 'grad_norm': 24.980613708496094, 'learning_rate': 0.0004477211796246649, 'epoch': 5.522788203753351}\n",
      "{'loss': 0.3564, 'grad_norm': 86.67951202392578, 'learning_rate': 0.00044638069705093836, 'epoch': 5.536193029490617}\n",
      "{'loss': 0.3974, 'grad_norm': 127.47535705566406, 'learning_rate': 0.0004450402144772118, 'epoch': 5.549597855227882}\n",
      "{'loss': 0.3766, 'grad_norm': 81.81410217285156, 'learning_rate': 0.0004436997319034853, 'epoch': 5.563002680965147}\n",
      "{'loss': 0.4398, 'grad_norm': 22.804954528808594, 'learning_rate': 0.00044235924932975874, 'epoch': 5.576407506702413}\n",
      "{'loss': 0.3358, 'grad_norm': 19.26137924194336, 'learning_rate': 0.0004410187667560322, 'epoch': 5.589812332439678}\n",
      "{'loss': 0.3751, 'grad_norm': 8.66801929473877, 'learning_rate': 0.00043967828418230566, 'epoch': 5.603217158176943}\n",
      "{'loss': 0.3375, 'grad_norm': 31.000240325927734, 'learning_rate': 0.0004383378016085791, 'epoch': 5.616621983914209}\n",
      "{'loss': 0.3856, 'grad_norm': 49.02517318725586, 'learning_rate': 0.0004369973190348526, 'epoch': 5.630026809651475}\n",
      "{'loss': 0.3509, 'grad_norm': 19.009920120239258, 'learning_rate': 0.00043565683646112604, 'epoch': 5.64343163538874}\n",
      "{'loss': 0.3488, 'grad_norm': 28.633636474609375, 'learning_rate': 0.0004343163538873995, 'epoch': 5.656836461126005}\n",
      "{'loss': 0.3459, 'grad_norm': 58.16763687133789, 'learning_rate': 0.00043297587131367295, 'epoch': 5.670241286863271}\n",
      "{'loss': 0.348, 'grad_norm': 28.04249382019043, 'learning_rate': 0.0004316353887399464, 'epoch': 5.683646112600536}\n",
      "{'loss': 0.3236, 'grad_norm': 18.118675231933594, 'learning_rate': 0.00043029490616621987, 'epoch': 5.697050938337801}\n",
      "{'loss': 0.3183, 'grad_norm': 29.94708251953125, 'learning_rate': 0.00042895442359249333, 'epoch': 5.710455764075067}\n",
      "{'loss': 0.3491, 'grad_norm': 32.85527420043945, 'learning_rate': 0.0004276139410187668, 'epoch': 5.7238605898123325}\n",
      "{'loss': 0.3681, 'grad_norm': 32.6750602722168, 'learning_rate': 0.00042627345844504025, 'epoch': 5.737265415549598}\n",
      "{'loss': 0.3185, 'grad_norm': 29.98786735534668, 'learning_rate': 0.0004249329758713137, 'epoch': 5.750670241286863}\n",
      "{'loss': 0.377, 'grad_norm': 47.7723388671875, 'learning_rate': 0.00042359249329758717, 'epoch': 5.7640750670241285}\n",
      "{'loss': 0.3391, 'grad_norm': 17.862533569335938, 'learning_rate': 0.0004222520107238606, 'epoch': 5.777479892761394}\n",
      "{'loss': 0.3455, 'grad_norm': 12.030333518981934, 'learning_rate': 0.0004209115281501341, 'epoch': 5.79088471849866}\n",
      "{'loss': 0.387, 'grad_norm': 63.67737579345703, 'learning_rate': 0.00041957104557640754, 'epoch': 5.804289544235925}\n",
      "{'loss': 0.3334, 'grad_norm': 42.12242126464844, 'learning_rate': 0.000418230563002681, 'epoch': 5.81769436997319}\n",
      "{'loss': 0.3385, 'grad_norm': 20.107481002807617, 'learning_rate': 0.00041689008042895446, 'epoch': 5.831099195710456}\n",
      "{'loss': 0.3406, 'grad_norm': 38.18539047241211, 'learning_rate': 0.00041554959785522786, 'epoch': 5.8445040214477215}\n",
      "{'loss': 0.3143, 'grad_norm': 42.487396240234375, 'learning_rate': 0.0004142091152815013, 'epoch': 5.857908847184986}\n",
      "{'loss': 0.3447, 'grad_norm': 24.0445556640625, 'learning_rate': 0.0004128686327077748, 'epoch': 5.871313672922252}\n",
      "{'loss': 0.3365, 'grad_norm': 44.55046463012695, 'learning_rate': 0.00041152815013404824, 'epoch': 5.884718498659518}\n",
      "{'loss': 0.3406, 'grad_norm': 18.963993072509766, 'learning_rate': 0.0004101876675603217, 'epoch': 5.898123324396783}\n",
      "{'loss': 0.32, 'grad_norm': 21.39095115661621, 'learning_rate': 0.00040884718498659516, 'epoch': 5.911528150134048}\n",
      "{'loss': 0.3459, 'grad_norm': 31.10356903076172, 'learning_rate': 0.0004075067024128686, 'epoch': 5.924932975871314}\n",
      "{'loss': 0.3393, 'grad_norm': 17.177772521972656, 'learning_rate': 0.0004061662198391421, 'epoch': 5.938337801608579}\n",
      "{'loss': 0.3302, 'grad_norm': 6.344754695892334, 'learning_rate': 0.00040482573726541553, 'epoch': 5.951742627345844}\n",
      "{'loss': 0.3114, 'grad_norm': 28.75965690612793, 'learning_rate': 0.000403485254691689, 'epoch': 5.96514745308311}\n",
      "{'loss': 0.3259, 'grad_norm': 14.839783668518066, 'learning_rate': 0.00040214477211796245, 'epoch': 5.978552278820375}\n",
      "{'loss': 0.3623, 'grad_norm': 16.44681167602539, 'learning_rate': 0.0004008042895442359, 'epoch': 5.991957104557641}\n",
      "{'eval_loss': 0.3258248269557953, 'eval_accuracy': 0.9, 'eval_runtime': 5.367, 'eval_samples_per_second': 119.247, 'eval_steps_per_second': 1.863, 'epoch': 6.0}\n",
      "{'loss': 0.3651, 'grad_norm': 5.438648223876953, 'learning_rate': 0.00039946380697050937, 'epoch': 6.005361930294906}\n",
      "{'loss': 0.3414, 'grad_norm': 45.961151123046875, 'learning_rate': 0.00039812332439678283, 'epoch': 6.018766756032171}\n",
      "{'loss': 0.3229, 'grad_norm': 20.6185302734375, 'learning_rate': 0.0003967828418230563, 'epoch': 6.032171581769437}\n",
      "{'loss': 0.2897, 'grad_norm': 8.084152221679688, 'learning_rate': 0.00039544235924932975, 'epoch': 6.045576407506703}\n",
      "{'loss': 0.3302, 'grad_norm': 40.032928466796875, 'learning_rate': 0.0003941018766756032, 'epoch': 6.058981233243967}\n",
      "{'loss': 0.3373, 'grad_norm': 28.576492309570312, 'learning_rate': 0.00039276139410187666, 'epoch': 6.072386058981233}\n",
      "{'loss': 0.3159, 'grad_norm': 13.249404907226562, 'learning_rate': 0.0003914209115281501, 'epoch': 6.085790884718499}\n",
      "{'loss': 0.3379, 'grad_norm': 20.6435604095459, 'learning_rate': 0.0003900804289544236, 'epoch': 6.099195710455764}\n",
      "{'loss': 0.3025, 'grad_norm': 2.8363373279571533, 'learning_rate': 0.00038873994638069704, 'epoch': 6.112600536193029}\n",
      "{'loss': 0.3601, 'grad_norm': 63.72832107543945, 'learning_rate': 0.0003873994638069705, 'epoch': 6.126005361930295}\n",
      "{'loss': 0.3484, 'grad_norm': 7.261415481567383, 'learning_rate': 0.00038605898123324396, 'epoch': 6.13941018766756}\n",
      "{'loss': 0.3022, 'grad_norm': 12.495609283447266, 'learning_rate': 0.0003847184986595174, 'epoch': 6.152815013404826}\n",
      "{'loss': 0.2983, 'grad_norm': 12.016468048095703, 'learning_rate': 0.0003833780160857909, 'epoch': 6.166219839142091}\n",
      "{'loss': 0.3085, 'grad_norm': 41.32468795776367, 'learning_rate': 0.00038203753351206434, 'epoch': 6.1796246648793565}\n",
      "{'loss': 0.3382, 'grad_norm': 16.36329460144043, 'learning_rate': 0.0003806970509383378, 'epoch': 6.193029490616622}\n",
      "{'loss': 0.3071, 'grad_norm': 12.009981155395508, 'learning_rate': 0.00037935656836461125, 'epoch': 6.206434316353888}\n",
      "{'loss': 0.3088, 'grad_norm': 25.07330894470215, 'learning_rate': 0.0003780160857908847, 'epoch': 6.2198391420911525}\n",
      "{'loss': 0.3184, 'grad_norm': 20.52521324157715, 'learning_rate': 0.00037667560321715817, 'epoch': 6.233243967828418}\n",
      "{'loss': 0.3343, 'grad_norm': 77.36647033691406, 'learning_rate': 0.00037533512064343163, 'epoch': 6.246648793565684}\n",
      "{'loss': 0.3166, 'grad_norm': 43.25499725341797, 'learning_rate': 0.00037399463806970514, 'epoch': 6.2600536193029495}\n",
      "{'loss': 0.3107, 'grad_norm': 117.8535385131836, 'learning_rate': 0.0003726541554959786, 'epoch': 6.273458445040214}\n",
      "{'loss': 0.3293, 'grad_norm': 64.25, 'learning_rate': 0.00037131367292225206, 'epoch': 6.28686327077748}\n",
      "{'loss': 0.3322, 'grad_norm': 27.030590057373047, 'learning_rate': 0.0003699731903485255, 'epoch': 6.3002680965147455}\n",
      "{'loss': 0.2983, 'grad_norm': 4.647134780883789, 'learning_rate': 0.000368632707774799, 'epoch': 6.31367292225201}\n",
      "{'loss': 0.357, 'grad_norm': 24.38950538635254, 'learning_rate': 0.00036729222520107244, 'epoch': 6.327077747989276}\n",
      "{'loss': 0.3135, 'grad_norm': 19.804641723632812, 'learning_rate': 0.0003659517426273459, 'epoch': 6.340482573726542}\n",
      "{'loss': 0.2968, 'grad_norm': 24.905717849731445, 'learning_rate': 0.00036461126005361935, 'epoch': 6.353887399463807}\n",
      "{'loss': 0.2948, 'grad_norm': 64.29261016845703, 'learning_rate': 0.0003632707774798928, 'epoch': 6.367292225201073}\n",
      "{'loss': 0.3212, 'grad_norm': 23.17022705078125, 'learning_rate': 0.00036193029490616627, 'epoch': 6.380697050938338}\n",
      "{'loss': 0.3252, 'grad_norm': 11.675164222717285, 'learning_rate': 0.0003605898123324397, 'epoch': 6.394101876675603}\n",
      "{'loss': 0.3245, 'grad_norm': 19.408489227294922, 'learning_rate': 0.00035924932975871314, 'epoch': 6.407506702412869}\n",
      "{'loss': 0.3191, 'grad_norm': 2.3807365894317627, 'learning_rate': 0.0003579088471849866, 'epoch': 6.420911528150134}\n",
      "{'loss': 0.3435, 'grad_norm': 29.649564743041992, 'learning_rate': 0.00035656836461126005, 'epoch': 6.434316353887399}\n",
      "{'loss': 0.3258, 'grad_norm': 30.97731590270996, 'learning_rate': 0.0003552278820375335, 'epoch': 6.447721179624665}\n",
      "{'loss': 0.3159, 'grad_norm': 18.792768478393555, 'learning_rate': 0.00035388739946380697, 'epoch': 6.461126005361931}\n",
      "{'loss': 0.2765, 'grad_norm': 7.514176368713379, 'learning_rate': 0.00035254691689008043, 'epoch': 6.474530831099195}\n",
      "{'loss': 0.3139, 'grad_norm': 10.614387512207031, 'learning_rate': 0.0003512064343163539, 'epoch': 6.487935656836461}\n",
      "{'loss': 0.3369, 'grad_norm': 18.42157554626465, 'learning_rate': 0.00034986595174262735, 'epoch': 6.501340482573727}\n",
      "{'loss': 0.3022, 'grad_norm': 12.401348114013672, 'learning_rate': 0.0003485254691689008, 'epoch': 6.514745308310992}\n",
      "{'loss': 0.3056, 'grad_norm': 13.269617080688477, 'learning_rate': 0.00034718498659517427, 'epoch': 6.528150134048257}\n",
      "{'loss': 0.3128, 'grad_norm': 36.45454025268555, 'learning_rate': 0.0003458445040214477, 'epoch': 6.541554959785523}\n",
      "{'loss': 0.3315, 'grad_norm': 12.808061599731445, 'learning_rate': 0.0003445040214477212, 'epoch': 6.554959785522788}\n",
      "{'loss': 0.2759, 'grad_norm': 35.619815826416016, 'learning_rate': 0.00034316353887399464, 'epoch': 6.568364611260054}\n",
      "{'loss': 0.3255, 'grad_norm': 23.78565216064453, 'learning_rate': 0.0003418230563002681, 'epoch': 6.581769436997319}\n",
      "{'loss': 0.31, 'grad_norm': 30.11074447631836, 'learning_rate': 0.00034048257372654156, 'epoch': 6.595174262734584}\n",
      "{'loss': 0.3512, 'grad_norm': 40.00959777832031, 'learning_rate': 0.000339142091152815, 'epoch': 6.60857908847185}\n",
      "{'loss': 0.3358, 'grad_norm': 6.8017401695251465, 'learning_rate': 0.0003378016085790885, 'epoch': 6.621983914209116}\n",
      "{'loss': 0.3206, 'grad_norm': 44.99169921875, 'learning_rate': 0.00033646112600536194, 'epoch': 6.6353887399463805}\n",
      "{'loss': 0.3701, 'grad_norm': 24.381792068481445, 'learning_rate': 0.0003351206434316354, 'epoch': 6.648793565683646}\n",
      "{'loss': 0.3374, 'grad_norm': 26.536787033081055, 'learning_rate': 0.00033378016085790885, 'epoch': 6.662198391420912}\n",
      "{'loss': 0.3248, 'grad_norm': 8.781648635864258, 'learning_rate': 0.0003324396782841823, 'epoch': 6.6756032171581765}\n",
      "{'loss': 0.3312, 'grad_norm': 13.10666561126709, 'learning_rate': 0.00033109919571045577, 'epoch': 6.689008042895442}\n",
      "{'loss': 0.3306, 'grad_norm': 11.055272102355957, 'learning_rate': 0.00032975871313672923, 'epoch': 6.702412868632708}\n",
      "{'loss': 0.3487, 'grad_norm': 37.527313232421875, 'learning_rate': 0.0003284182305630027, 'epoch': 6.7158176943699734}\n",
      "{'loss': 0.3111, 'grad_norm': 14.080514907836914, 'learning_rate': 0.00032707774798927615, 'epoch': 6.729222520107239}\n",
      "{'loss': 0.2658, 'grad_norm': 36.9266242980957, 'learning_rate': 0.0003257372654155496, 'epoch': 6.742627345844504}\n",
      "{'loss': 0.3344, 'grad_norm': 10.853958129882812, 'learning_rate': 0.00032439678284182307, 'epoch': 6.7560321715817695}\n",
      "{'loss': 0.301, 'grad_norm': 10.535591125488281, 'learning_rate': 0.0003230563002680965, 'epoch': 6.769436997319035}\n",
      "{'loss': 0.3182, 'grad_norm': 16.8060245513916, 'learning_rate': 0.00032171581769437, 'epoch': 6.7828418230563}\n",
      "{'loss': 0.3328, 'grad_norm': 5.336742877960205, 'learning_rate': 0.00032037533512064344, 'epoch': 6.7962466487935655}\n",
      "{'loss': 0.2753, 'grad_norm': 21.054670333862305, 'learning_rate': 0.0003190348525469169, 'epoch': 6.809651474530831}\n",
      "{'loss': 0.3277, 'grad_norm': 17.381338119506836, 'learning_rate': 0.00031769436997319036, 'epoch': 6.823056300268097}\n",
      "{'loss': 0.3232, 'grad_norm': 18.158571243286133, 'learning_rate': 0.0003163538873994638, 'epoch': 6.836461126005362}\n",
      "{'loss': 0.2947, 'grad_norm': 16.432514190673828, 'learning_rate': 0.0003150134048257373, 'epoch': 6.849865951742627}\n",
      "{'loss': 0.3529, 'grad_norm': 9.26707649230957, 'learning_rate': 0.00031367292225201074, 'epoch': 6.863270777479893}\n",
      "{'loss': 0.3041, 'grad_norm': 11.720663070678711, 'learning_rate': 0.0003123324396782842, 'epoch': 6.8766756032171585}\n",
      "{'loss': 0.3191, 'grad_norm': 15.336212158203125, 'learning_rate': 0.00031099195710455765, 'epoch': 6.890080428954423}\n",
      "{'loss': 0.2934, 'grad_norm': 13.943053245544434, 'learning_rate': 0.0003096514745308311, 'epoch': 6.903485254691689}\n",
      "{'loss': 0.3081, 'grad_norm': 19.153615951538086, 'learning_rate': 0.00030831099195710457, 'epoch': 6.916890080428955}\n",
      "{'loss': 0.3205, 'grad_norm': 20.993677139282227, 'learning_rate': 0.00030697050938337803, 'epoch': 6.930294906166219}\n",
      "{'loss': 0.324, 'grad_norm': 13.838055610656738, 'learning_rate': 0.00030563002680965144, 'epoch': 6.943699731903485}\n",
      "{'loss': 0.3099, 'grad_norm': 16.27643394470215, 'learning_rate': 0.0003042895442359249, 'epoch': 6.957104557640751}\n",
      "{'loss': 0.3011, 'grad_norm': 17.464740753173828, 'learning_rate': 0.00030294906166219835, 'epoch': 6.970509383378016}\n",
      "{'loss': 0.3409, 'grad_norm': 17.742755889892578, 'learning_rate': 0.0003016085790884718, 'epoch': 6.983914209115282}\n",
      "{'loss': 0.3312, 'grad_norm': 16.50057601928711, 'learning_rate': 0.00030026809651474527, 'epoch': 6.997319034852547}\n",
      "{'eval_loss': 0.30298781394958496, 'eval_accuracy': 0.90625, 'eval_runtime': 5.349, 'eval_samples_per_second': 119.65, 'eval_steps_per_second': 1.87, 'epoch': 7.0}\n",
      "{'loss': 0.3283, 'grad_norm': 14.367941856384277, 'learning_rate': 0.00029892761394101873, 'epoch': 7.010723860589812}\n",
      "{'loss': 0.2719, 'grad_norm': 17.327545166015625, 'learning_rate': 0.0002975871313672922, 'epoch': 7.024128686327078}\n",
      "{'loss': 0.3055, 'grad_norm': 13.07096004486084, 'learning_rate': 0.00029624664879356565, 'epoch': 7.037533512064343}\n",
      "{'loss': 0.336, 'grad_norm': 3.269761562347412, 'learning_rate': 0.0002949061662198391, 'epoch': 7.050938337801608}\n",
      "{'loss': 0.2918, 'grad_norm': 17.103118896484375, 'learning_rate': 0.00029356568364611257, 'epoch': 7.064343163538874}\n",
      "{'loss': 0.2711, 'grad_norm': 15.202774047851562, 'learning_rate': 0.000292225201072386, 'epoch': 7.07774798927614}\n",
      "{'loss': 0.3244, 'grad_norm': 80.275146484375, 'learning_rate': 0.00029088471849865954, 'epoch': 7.091152815013404}\n",
      "{'loss': 0.3145, 'grad_norm': 16.234066009521484, 'learning_rate': 0.000289544235924933, 'epoch': 7.10455764075067}\n",
      "{'loss': 0.3318, 'grad_norm': 11.005657196044922, 'learning_rate': 0.00028820375335120645, 'epoch': 7.117962466487936}\n",
      "{'loss': 0.3185, 'grad_norm': 29.96757698059082, 'learning_rate': 0.0002868632707774799, 'epoch': 7.131367292225201}\n",
      "{'loss': 0.3321, 'grad_norm': 19.73541259765625, 'learning_rate': 0.00028552278820375337, 'epoch': 7.144772117962466}\n",
      "{'loss': 0.2964, 'grad_norm': 59.62905502319336, 'learning_rate': 0.00028418230563002683, 'epoch': 7.158176943699732}\n",
      "{'loss': 0.2903, 'grad_norm': 88.5110855102539, 'learning_rate': 0.0002828418230563003, 'epoch': 7.171581769436997}\n",
      "{'loss': 0.3031, 'grad_norm': 4.306055068969727, 'learning_rate': 0.00028150134048257375, 'epoch': 7.184986595174263}\n",
      "{'loss': 0.3131, 'grad_norm': 49.51044464111328, 'learning_rate': 0.0002801608579088472, 'epoch': 7.198391420911528}\n",
      "{'loss': 0.3097, 'grad_norm': 20.802324295043945, 'learning_rate': 0.00027882037533512067, 'epoch': 7.2117962466487935}\n",
      "{'loss': 0.2958, 'grad_norm': 17.627695083618164, 'learning_rate': 0.0002774798927613941, 'epoch': 7.225201072386059}\n",
      "{'loss': 0.3353, 'grad_norm': 64.25257110595703, 'learning_rate': 0.0002761394101876676, 'epoch': 7.238605898123325}\n",
      "{'loss': 0.2774, 'grad_norm': 12.420038223266602, 'learning_rate': 0.00027479892761394104, 'epoch': 7.2520107238605895}\n",
      "{'loss': 0.3046, 'grad_norm': 13.701875686645508, 'learning_rate': 0.0002734584450402145, 'epoch': 7.265415549597855}\n",
      "{'loss': 0.3521, 'grad_norm': 16.172746658325195, 'learning_rate': 0.00027211796246648796, 'epoch': 7.278820375335121}\n",
      "{'loss': 0.2984, 'grad_norm': 7.11234712600708, 'learning_rate': 0.0002707774798927614, 'epoch': 7.292225201072386}\n",
      "{'loss': 0.3278, 'grad_norm': 174.9019775390625, 'learning_rate': 0.0002694369973190349, 'epoch': 7.305630026809651}\n",
      "{'loss': 0.3126, 'grad_norm': 85.28077697753906, 'learning_rate': 0.00026809651474530834, 'epoch': 7.319034852546917}\n",
      "{'loss': 0.3307, 'grad_norm': 15.442093849182129, 'learning_rate': 0.0002667560321715818, 'epoch': 7.3324396782841825}\n",
      "{'loss': 0.3166, 'grad_norm': 21.320383071899414, 'learning_rate': 0.00026541554959785526, 'epoch': 7.345844504021448}\n",
      "{'loss': 0.3233, 'grad_norm': 180.2035675048828, 'learning_rate': 0.0002640750670241287, 'epoch': 7.359249329758713}\n",
      "{'loss': 0.3307, 'grad_norm': 22.961029052734375, 'learning_rate': 0.0002627345844504022, 'epoch': 7.372654155495979}\n",
      "{'loss': 0.2899, 'grad_norm': 21.662433624267578, 'learning_rate': 0.00026139410187667563, 'epoch': 7.386058981233244}\n",
      "{'loss': 0.3277, 'grad_norm': 12.972709655761719, 'learning_rate': 0.0002600536193029491, 'epoch': 7.399463806970509}\n",
      "{'loss': 0.2856, 'grad_norm': 22.616941452026367, 'learning_rate': 0.00025871313672922255, 'epoch': 7.412868632707775}\n",
      "{'loss': 0.3386, 'grad_norm': 16.529157638549805, 'learning_rate': 0.000257372654155496, 'epoch': 7.42627345844504}\n",
      "{'loss': 0.321, 'grad_norm': 24.347591400146484, 'learning_rate': 0.00025603217158176947, 'epoch': 7.439678284182306}\n",
      "{'loss': 0.3006, 'grad_norm': 19.896699905395508, 'learning_rate': 0.0002546916890080429, 'epoch': 7.453083109919571}\n",
      "{'loss': 0.3223, 'grad_norm': 34.53056716918945, 'learning_rate': 0.0002533512064343164, 'epoch': 7.466487935656836}\n",
      "{'loss': 0.2884, 'grad_norm': 37.79254150390625, 'learning_rate': 0.00025201072386058984, 'epoch': 7.479892761394102}\n",
      "{'loss': 0.3021, 'grad_norm': 16.874435424804688, 'learning_rate': 0.0002506702412868633, 'epoch': 7.493297587131368}\n",
      "{'loss': 0.298, 'grad_norm': 10.1257905960083, 'learning_rate': 0.0002493297587131367, 'epoch': 7.506702412868632}\n",
      "{'loss': 0.3005, 'grad_norm': 29.059589385986328, 'learning_rate': 0.00024798927613941017, 'epoch': 7.520107238605898}\n",
      "{'loss': 0.297, 'grad_norm': 30.928546905517578, 'learning_rate': 0.0002466487935656836, 'epoch': 7.533512064343164}\n",
      "{'loss': 0.341, 'grad_norm': 20.948041915893555, 'learning_rate': 0.0002453083109919571, 'epoch': 7.546916890080429}\n",
      "{'loss': 0.3141, 'grad_norm': 14.736867904663086, 'learning_rate': 0.00024396782841823057, 'epoch': 7.560321715817694}\n",
      "{'loss': 0.2675, 'grad_norm': 14.836112022399902, 'learning_rate': 0.00024262734584450403, 'epoch': 7.57372654155496}\n",
      "{'loss': 0.2984, 'grad_norm': 47.6250114440918, 'learning_rate': 0.0002412868632707775, 'epoch': 7.587131367292225}\n",
      "{'loss': 0.316, 'grad_norm': 28.08035659790039, 'learning_rate': 0.00023994638069705095, 'epoch': 7.600536193029491}\n",
      "{'loss': 0.3215, 'grad_norm': 7.591454029083252, 'learning_rate': 0.0002386058981233244, 'epoch': 7.613941018766756}\n",
      "{'loss': 0.2907, 'grad_norm': 12.35313892364502, 'learning_rate': 0.00023726541554959786, 'epoch': 7.627345844504021}\n",
      "{'loss': 0.3142, 'grad_norm': 5.617504596710205, 'learning_rate': 0.0002359249329758713, 'epoch': 7.640750670241287}\n",
      "{'loss': 0.3264, 'grad_norm': 7.444458961486816, 'learning_rate': 0.00023458445040214475, 'epoch': 7.654155495978552}\n",
      "{'loss': 0.2773, 'grad_norm': 20.812053680419922, 'learning_rate': 0.00023324396782841821, 'epoch': 7.6675603217158175}\n",
      "{'loss': 0.2806, 'grad_norm': 17.23301887512207, 'learning_rate': 0.00023190348525469167, 'epoch': 7.680965147453083}\n",
      "{'loss': 0.2822, 'grad_norm': 128.514404296875, 'learning_rate': 0.00023056300268096513, 'epoch': 7.694369973190349}\n",
      "{'loss': 0.3072, 'grad_norm': 28.57379913330078, 'learning_rate': 0.0002292225201072386, 'epoch': 7.707774798927614}\n",
      "{'loss': 0.3322, 'grad_norm': 10.356613159179688, 'learning_rate': 0.00022788203753351208, 'epoch': 7.721179624664879}\n",
      "{'loss': 0.3011, 'grad_norm': 8.595948219299316, 'learning_rate': 0.00022654155495978554, 'epoch': 7.734584450402145}\n",
      "{'loss': 0.333, 'grad_norm': 5.174045562744141, 'learning_rate': 0.000225201072386059, 'epoch': 7.7479892761394105}\n",
      "{'loss': 0.2978, 'grad_norm': 9.950383186340332, 'learning_rate': 0.00022386058981233245, 'epoch': 7.761394101876675}\n",
      "{'loss': 0.3308, 'grad_norm': 422.6626281738281, 'learning_rate': 0.0002225201072386059, 'epoch': 7.774798927613941}\n",
      "{'loss': 0.2594, 'grad_norm': 6.003878593444824, 'learning_rate': 0.00022117962466487937, 'epoch': 7.7882037533512065}\n",
      "{'loss': 0.3092, 'grad_norm': 14.692179679870605, 'learning_rate': 0.00021983914209115283, 'epoch': 7.801608579088472}\n",
      "{'loss': 0.3181, 'grad_norm': 8.230615615844727, 'learning_rate': 0.0002184986595174263, 'epoch': 7.815013404825737}\n",
      "{'loss': 0.2862, 'grad_norm': 25.852724075317383, 'learning_rate': 0.00021715817694369975, 'epoch': 7.828418230563003}\n",
      "{'loss': 0.319, 'grad_norm': 19.450326919555664, 'learning_rate': 0.0002158176943699732, 'epoch': 7.841823056300268}\n",
      "{'loss': 0.3293, 'grad_norm': 21.96885871887207, 'learning_rate': 0.00021447721179624666, 'epoch': 7.855227882037534}\n",
      "{'loss': 0.2792, 'grad_norm': 19.55544662475586, 'learning_rate': 0.00021313672922252012, 'epoch': 7.868632707774799}\n",
      "{'loss': 0.3078, 'grad_norm': 93.24164581298828, 'learning_rate': 0.00021179624664879358, 'epoch': 7.882037533512064}\n",
      "{'loss': 0.2978, 'grad_norm': 10.226283073425293, 'learning_rate': 0.00021045576407506704, 'epoch': 7.89544235924933}\n",
      "{'loss': 0.3284, 'grad_norm': 43.99352264404297, 'learning_rate': 0.0002091152815013405, 'epoch': 7.908847184986596}\n",
      "{'loss': 0.2943, 'grad_norm': 59.173728942871094, 'learning_rate': 0.00020777479892761393, 'epoch': 7.92225201072386}\n",
      "{'loss': 0.3436, 'grad_norm': 41.344337463378906, 'learning_rate': 0.0002064343163538874, 'epoch': 7.935656836461126}\n",
      "{'loss': 0.3191, 'grad_norm': 6.714873313903809, 'learning_rate': 0.00020509383378016085, 'epoch': 7.949061662198392}\n",
      "{'loss': 0.2784, 'grad_norm': 14.659293174743652, 'learning_rate': 0.0002037533512064343, 'epoch': 7.962466487935657}\n",
      "{'loss': 0.2769, 'grad_norm': 11.53768539428711, 'learning_rate': 0.00020241286863270777, 'epoch': 7.975871313672922}\n",
      "{'loss': 0.3154, 'grad_norm': 54.91364288330078, 'learning_rate': 0.00020107238605898123, 'epoch': 7.989276139410188}\n",
      "{'eval_loss': 0.27676814794540405, 'eval_accuracy': 0.9078125, 'eval_runtime': 5.3931, 'eval_samples_per_second': 118.669, 'eval_steps_per_second': 1.854, 'epoch': 8.0}\n",
      "{'loss': 0.3173, 'grad_norm': 9.210466384887695, 'learning_rate': 0.00019973190348525469, 'epoch': 8.002680965147453}\n",
      "{'loss': 0.2861, 'grad_norm': 24.41217803955078, 'learning_rate': 0.00019839142091152814, 'epoch': 8.016085790884718}\n",
      "{'loss': 0.2681, 'grad_norm': 26.606355667114258, 'learning_rate': 0.0001970509383378016, 'epoch': 8.029490616621985}\n",
      "{'loss': 0.2958, 'grad_norm': 1.7093631029129028, 'learning_rate': 0.00019571045576407506, 'epoch': 8.04289544235925}\n",
      "{'loss': 0.2622, 'grad_norm': 19.320568084716797, 'learning_rate': 0.00019436997319034852, 'epoch': 8.056300268096514}\n",
      "{'loss': 0.2583, 'grad_norm': 68.738525390625, 'learning_rate': 0.00019302949061662198, 'epoch': 8.06970509383378}\n",
      "{'loss': 0.2707, 'grad_norm': 24.678800582885742, 'learning_rate': 0.00019168900804289544, 'epoch': 8.083109919571045}\n",
      "{'loss': 0.2982, 'grad_norm': 25.101261138916016, 'learning_rate': 0.0001903485254691689, 'epoch': 8.09651474530831}\n",
      "{'loss': 0.2994, 'grad_norm': 12.47732925415039, 'learning_rate': 0.00018900804289544236, 'epoch': 8.109919571045577}\n",
      "{'loss': 0.296, 'grad_norm': 75.41675567626953, 'learning_rate': 0.00018766756032171581, 'epoch': 8.123324396782841}\n",
      "{'loss': 0.3084, 'grad_norm': 31.68948745727539, 'learning_rate': 0.0001863270777479893, 'epoch': 8.136729222520108}\n",
      "{'loss': 0.2873, 'grad_norm': 14.295001983642578, 'learning_rate': 0.00018498659517426276, 'epoch': 8.150134048257373}\n",
      "{'loss': 0.2734, 'grad_norm': 21.211807250976562, 'learning_rate': 0.00018364611260053622, 'epoch': 8.163538873994638}\n",
      "{'loss': 0.2888, 'grad_norm': 29.144548416137695, 'learning_rate': 0.00018230563002680968, 'epoch': 8.176943699731904}\n",
      "{'loss': 0.2865, 'grad_norm': 19.719493865966797, 'learning_rate': 0.00018096514745308314, 'epoch': 8.190348525469169}\n",
      "{'loss': 0.2664, 'grad_norm': 14.275660514831543, 'learning_rate': 0.00017962466487935657, 'epoch': 8.203753351206434}\n",
      "{'loss': 0.3074, 'grad_norm': 28.553192138671875, 'learning_rate': 0.00017828418230563003, 'epoch': 8.2171581769437}\n",
      "{'loss': 0.3041, 'grad_norm': 56.224578857421875, 'learning_rate': 0.00017694369973190349, 'epoch': 8.230563002680965}\n",
      "{'loss': 0.2996, 'grad_norm': 10.520737648010254, 'learning_rate': 0.00017560321715817694, 'epoch': 8.243967828418231}\n",
      "{'loss': 0.2796, 'grad_norm': 14.131166458129883, 'learning_rate': 0.0001742627345844504, 'epoch': 8.257372654155496}\n",
      "{'loss': 0.3478, 'grad_norm': 21.982812881469727, 'learning_rate': 0.00017292225201072386, 'epoch': 8.270777479892761}\n",
      "{'loss': 0.313, 'grad_norm': 28.69530487060547, 'learning_rate': 0.00017158176943699732, 'epoch': 8.284182305630027}\n",
      "{'loss': 0.2798, 'grad_norm': 1.2088996171951294, 'learning_rate': 0.00017024128686327078, 'epoch': 8.297587131367292}\n",
      "{'loss': 0.3048, 'grad_norm': 11.098600387573242, 'learning_rate': 0.00016890080428954424, 'epoch': 8.310991957104557}\n",
      "{'loss': 0.2693, 'grad_norm': 5.783869743347168, 'learning_rate': 0.0001675603217158177, 'epoch': 8.324396782841823}\n",
      "{'loss': 0.3137, 'grad_norm': 21.453369140625, 'learning_rate': 0.00016621983914209116, 'epoch': 8.337801608579088}\n",
      "{'loss': 0.3416, 'grad_norm': 128.72544860839844, 'learning_rate': 0.00016487935656836462, 'epoch': 8.351206434316353}\n",
      "{'loss': 0.2986, 'grad_norm': 24.931489944458008, 'learning_rate': 0.00016353887399463807, 'epoch': 8.36461126005362}\n",
      "{'loss': 0.3351, 'grad_norm': 14.716170310974121, 'learning_rate': 0.00016219839142091153, 'epoch': 8.378016085790884}\n",
      "{'loss': 0.304, 'grad_norm': 61.23029327392578, 'learning_rate': 0.000160857908847185, 'epoch': 8.39142091152815}\n",
      "{'loss': 0.2867, 'grad_norm': 33.46459197998047, 'learning_rate': 0.00015951742627345845, 'epoch': 8.404825737265416}\n",
      "{'loss': 0.2979, 'grad_norm': 14.284329414367676, 'learning_rate': 0.0001581769436997319, 'epoch': 8.41823056300268}\n",
      "{'loss': 0.3293, 'grad_norm': 4.63293981552124, 'learning_rate': 0.00015683646112600537, 'epoch': 8.431635388739947}\n",
      "{'loss': 0.3036, 'grad_norm': 7.401068210601807, 'learning_rate': 0.00015549597855227883, 'epoch': 8.445040214477212}\n",
      "{'loss': 0.2697, 'grad_norm': 16.284523010253906, 'learning_rate': 0.00015415549597855229, 'epoch': 8.458445040214476}\n",
      "{'loss': 0.2976, 'grad_norm': 43.79189682006836, 'learning_rate': 0.00015281501340482572, 'epoch': 8.471849865951743}\n",
      "{'loss': 0.2765, 'grad_norm': 3.1221044063568115, 'learning_rate': 0.00015147453083109918, 'epoch': 8.485254691689008}\n",
      "{'loss': 0.3174, 'grad_norm': 74.29240417480469, 'learning_rate': 0.00015013404825737264, 'epoch': 8.498659517426274}\n",
      "{'loss': 0.3141, 'grad_norm': 73.88689422607422, 'learning_rate': 0.0001487935656836461, 'epoch': 8.512064343163539}\n",
      "{'loss': 0.2824, 'grad_norm': 13.505735397338867, 'learning_rate': 0.00014745308310991955, 'epoch': 8.525469168900804}\n",
      "{'loss': 0.2575, 'grad_norm': 8.364740371704102, 'learning_rate': 0.000146112600536193, 'epoch': 8.53887399463807}\n",
      "{'loss': 0.3236, 'grad_norm': 3.017756700515747, 'learning_rate': 0.0001447721179624665, 'epoch': 8.552278820375335}\n",
      "{'loss': 0.2479, 'grad_norm': 3.7392070293426514, 'learning_rate': 0.00014343163538873996, 'epoch': 8.5656836461126}\n",
      "{'loss': 0.2786, 'grad_norm': 7.37159538269043, 'learning_rate': 0.00014209115281501342, 'epoch': 8.579088471849866}\n",
      "{'loss': 0.308, 'grad_norm': 18.251989364624023, 'learning_rate': 0.00014075067024128687, 'epoch': 8.592493297587131}\n",
      "{'loss': 0.3059, 'grad_norm': 20.197046279907227, 'learning_rate': 0.00013941018766756033, 'epoch': 8.605898123324398}\n",
      "{'loss': 0.3471, 'grad_norm': 46.88291931152344, 'learning_rate': 0.0001380697050938338, 'epoch': 8.619302949061662}\n",
      "{'loss': 0.2746, 'grad_norm': 34.58049774169922, 'learning_rate': 0.00013672922252010725, 'epoch': 8.632707774798927}\n",
      "{'loss': 0.2983, 'grad_norm': 2.255018472671509, 'learning_rate': 0.0001353887399463807, 'epoch': 8.646112600536194}\n",
      "{'loss': 0.328, 'grad_norm': 38.10212707519531, 'learning_rate': 0.00013404825737265417, 'epoch': 8.659517426273458}\n",
      "{'loss': 0.2987, 'grad_norm': 27.78803253173828, 'learning_rate': 0.00013270777479892763, 'epoch': 8.672922252010723}\n",
      "{'loss': 0.2648, 'grad_norm': 22.040180206298828, 'learning_rate': 0.0001313672922252011, 'epoch': 8.68632707774799}\n",
      "{'loss': 0.2784, 'grad_norm': 36.75000762939453, 'learning_rate': 0.00013002680965147455, 'epoch': 8.699731903485254}\n",
      "{'loss': 0.305, 'grad_norm': 6.584259033203125, 'learning_rate': 0.000128686327077748, 'epoch': 8.71313672922252}\n",
      "{'loss': 0.266, 'grad_norm': 15.97609806060791, 'learning_rate': 0.00012734584450402146, 'epoch': 8.726541554959786}\n",
      "{'loss': 0.3124, 'grad_norm': 27.04360008239746, 'learning_rate': 0.00012600536193029492, 'epoch': 8.73994638069705}\n",
      "{'loss': 0.2735, 'grad_norm': 0.8179150223731995, 'learning_rate': 0.00012466487935656835, 'epoch': 8.753351206434317}\n",
      "{'loss': 0.2591, 'grad_norm': 6.6155805587768555, 'learning_rate': 0.0001233243967828418, 'epoch': 8.766756032171582}\n",
      "{'loss': 0.2731, 'grad_norm': 10.99238395690918, 'learning_rate': 0.00012198391420911529, 'epoch': 8.780160857908847}\n",
      "{'loss': 0.2623, 'grad_norm': 9.345052719116211, 'learning_rate': 0.00012064343163538874, 'epoch': 8.793565683646113}\n",
      "{'loss': 0.2982, 'grad_norm': 16.939407348632812, 'learning_rate': 0.0001193029490616622, 'epoch': 8.806970509383378}\n",
      "{'loss': 0.3017, 'grad_norm': 40.06755828857422, 'learning_rate': 0.00011796246648793565, 'epoch': 8.820375335120643}\n",
      "{'loss': 0.2714, 'grad_norm': 9.106046676635742, 'learning_rate': 0.00011662198391420911, 'epoch': 8.83378016085791}\n",
      "{'loss': 0.2721, 'grad_norm': 9.921478271484375, 'learning_rate': 0.00011528150134048257, 'epoch': 8.847184986595174}\n",
      "{'loss': 0.272, 'grad_norm': 0.7804799675941467, 'learning_rate': 0.00011394101876675604, 'epoch': 8.86058981233244}\n",
      "{'loss': 0.2687, 'grad_norm': 16.02266502380371, 'learning_rate': 0.0001126005361930295, 'epoch': 8.873994638069705}\n",
      "{'loss': 0.2949, 'grad_norm': 3.6856236457824707, 'learning_rate': 0.00011126005361930296, 'epoch': 8.88739946380697}\n",
      "{'loss': 0.2924, 'grad_norm': 8.250960350036621, 'learning_rate': 0.00010991957104557641, 'epoch': 8.900804289544237}\n",
      "{'loss': 0.2682, 'grad_norm': 24.9863338470459, 'learning_rate': 0.00010857908847184987, 'epoch': 8.914209115281501}\n",
      "{'loss': 0.3188, 'grad_norm': 26.0715389251709, 'learning_rate': 0.00010723860589812333, 'epoch': 8.927613941018766}\n",
      "{'loss': 0.287, 'grad_norm': 20.164424896240234, 'learning_rate': 0.00010589812332439679, 'epoch': 8.941018766756033}\n",
      "{'loss': 0.298, 'grad_norm': 32.28252410888672, 'learning_rate': 0.00010455764075067025, 'epoch': 8.954423592493297}\n",
      "{'loss': 0.3054, 'grad_norm': 14.249909400939941, 'learning_rate': 0.0001032171581769437, 'epoch': 8.967828418230564}\n",
      "{'loss': 0.2866, 'grad_norm': 13.137860298156738, 'learning_rate': 0.00010187667560321715, 'epoch': 8.981233243967829}\n",
      "{'loss': 0.2682, 'grad_norm': 7.074732780456543, 'learning_rate': 0.00010053619302949061, 'epoch': 8.994638069705093}\n",
      "{'eval_loss': 0.2949950098991394, 'eval_accuracy': 0.9015625, 'eval_runtime': 5.3706, 'eval_samples_per_second': 119.167, 'eval_steps_per_second': 1.862, 'epoch': 9.0}\n",
      "{'loss': 0.2954, 'grad_norm': 31.969497680664062, 'learning_rate': 9.919571045576407e-05, 'epoch': 9.00804289544236}\n",
      "{'loss': 0.2635, 'grad_norm': 17.54435157775879, 'learning_rate': 9.785522788203753e-05, 'epoch': 9.021447721179625}\n",
      "{'loss': 0.2786, 'grad_norm': 16.352907180786133, 'learning_rate': 9.651474530831099e-05, 'epoch': 9.03485254691689}\n",
      "{'loss': 0.2841, 'grad_norm': 5.108768463134766, 'learning_rate': 9.517426273458445e-05, 'epoch': 9.048257372654156}\n",
      "{'loss': 0.2526, 'grad_norm': 37.05105209350586, 'learning_rate': 9.383378016085791e-05, 'epoch': 9.06166219839142}\n",
      "{'loss': 0.2782, 'grad_norm': 36.394325256347656, 'learning_rate': 9.249329758713138e-05, 'epoch': 9.075067024128685}\n",
      "{'loss': 0.2622, 'grad_norm': 26.10759925842285, 'learning_rate': 9.115281501340484e-05, 'epoch': 9.088471849865952}\n",
      "{'loss': 0.2684, 'grad_norm': 19.857540130615234, 'learning_rate': 8.981233243967828e-05, 'epoch': 9.101876675603217}\n",
      "{'loss': 0.3105, 'grad_norm': 17.266660690307617, 'learning_rate': 8.847184986595174e-05, 'epoch': 9.115281501340483}\n",
      "{'loss': 0.2492, 'grad_norm': 25.520170211791992, 'learning_rate': 8.71313672922252e-05, 'epoch': 9.128686327077748}\n",
      "{'loss': 0.2952, 'grad_norm': 28.071271896362305, 'learning_rate': 8.579088471849866e-05, 'epoch': 9.142091152815013}\n",
      "{'loss': 0.2961, 'grad_norm': 9.169778823852539, 'learning_rate': 8.445040214477212e-05, 'epoch': 9.15549597855228}\n",
      "{'loss': 0.2848, 'grad_norm': 20.560144424438477, 'learning_rate': 8.310991957104558e-05, 'epoch': 9.168900804289544}\n",
      "{'loss': 0.2682, 'grad_norm': 1.3023607730865479, 'learning_rate': 8.176943699731904e-05, 'epoch': 9.182305630026809}\n",
      "{'loss': 0.2999, 'grad_norm': 1.6456331014633179, 'learning_rate': 8.04289544235925e-05, 'epoch': 9.195710455764075}\n",
      "{'loss': 0.28, 'grad_norm': 25.691171646118164, 'learning_rate': 7.908847184986595e-05, 'epoch': 9.20911528150134}\n",
      "{'loss': 0.2897, 'grad_norm': 14.28453540802002, 'learning_rate': 7.774798927613941e-05, 'epoch': 9.222520107238607}\n",
      "{'loss': 0.2665, 'grad_norm': 111.09736633300781, 'learning_rate': 7.640750670241286e-05, 'epoch': 9.235924932975871}\n",
      "{'loss': 0.2936, 'grad_norm': 51.625579833984375, 'learning_rate': 7.506702412868632e-05, 'epoch': 9.249329758713136}\n",
      "{'loss': 0.2714, 'grad_norm': 21.560577392578125, 'learning_rate': 7.372654155495978e-05, 'epoch': 9.262734584450403}\n",
      "{'loss': 0.3079, 'grad_norm': 10.268884658813477, 'learning_rate': 7.238605898123325e-05, 'epoch': 9.276139410187668}\n",
      "{'loss': 0.2912, 'grad_norm': 6.532961845397949, 'learning_rate': 7.104557640750671e-05, 'epoch': 9.289544235924932}\n",
      "{'loss': 0.2913, 'grad_norm': 23.534292221069336, 'learning_rate': 6.970509383378017e-05, 'epoch': 9.302949061662199}\n",
      "{'loss': 0.2559, 'grad_norm': 8.179028511047363, 'learning_rate': 6.836461126005363e-05, 'epoch': 9.316353887399464}\n",
      "{'loss': 0.2569, 'grad_norm': 19.92439842224121, 'learning_rate': 6.702412868632708e-05, 'epoch': 9.32975871313673}\n",
      "{'loss': 0.2864, 'grad_norm': 18.846637725830078, 'learning_rate': 6.568364611260054e-05, 'epoch': 9.343163538873995}\n",
      "{'loss': 0.2665, 'grad_norm': 1.3337761163711548, 'learning_rate': 6.4343163538874e-05, 'epoch': 9.35656836461126}\n",
      "{'loss': 0.2871, 'grad_norm': 11.398844718933105, 'learning_rate': 6.300268096514746e-05, 'epoch': 9.369973190348526}\n",
      "{'loss': 0.2686, 'grad_norm': 9.42969036102295, 'learning_rate': 6.16621983914209e-05, 'epoch': 9.383378016085791}\n",
      "{'loss': 0.2671, 'grad_norm': 6.355199337005615, 'learning_rate': 6.032171581769437e-05, 'epoch': 9.396782841823056}\n",
      "{'loss': 0.2717, 'grad_norm': 8.072928428649902, 'learning_rate': 5.8981233243967824e-05, 'epoch': 9.410187667560322}\n",
      "{'loss': 0.2841, 'grad_norm': 16.650381088256836, 'learning_rate': 5.764075067024128e-05, 'epoch': 9.423592493297587}\n",
      "{'loss': 0.2849, 'grad_norm': 6.551784515380859, 'learning_rate': 5.630026809651475e-05, 'epoch': 9.436997319034852}\n",
      "{'loss': 0.29, 'grad_norm': 14.425899505615234, 'learning_rate': 5.495978552278821e-05, 'epoch': 9.450402144772118}\n",
      "{'loss': 0.2698, 'grad_norm': 62.50849914550781, 'learning_rate': 5.3619302949061666e-05, 'epoch': 9.463806970509383}\n",
      "{'loss': 0.2922, 'grad_norm': 59.34808349609375, 'learning_rate': 5.2278820375335125e-05, 'epoch': 9.47721179624665}\n",
      "{'loss': 0.2833, 'grad_norm': 18.010046005249023, 'learning_rate': 5.093833780160858e-05, 'epoch': 9.490616621983914}\n",
      "{'loss': 0.2806, 'grad_norm': 18.74396514892578, 'learning_rate': 4.9597855227882036e-05, 'epoch': 9.504021447721179}\n",
      "{'loss': 0.3111, 'grad_norm': 74.63569641113281, 'learning_rate': 4.8257372654155495e-05, 'epoch': 9.517426273458446}\n",
      "{'loss': 0.2734, 'grad_norm': 28.93852996826172, 'learning_rate': 4.6916890080428954e-05, 'epoch': 9.53083109919571}\n",
      "{'loss': 0.2644, 'grad_norm': 19.512813568115234, 'learning_rate': 4.557640750670242e-05, 'epoch': 9.544235924932975}\n",
      "{'loss': 0.3007, 'grad_norm': 8.610851287841797, 'learning_rate': 4.423592493297587e-05, 'epoch': 9.557640750670242}\n",
      "{'loss': 0.2949, 'grad_norm': 18.407976150512695, 'learning_rate': 4.289544235924933e-05, 'epoch': 9.571045576407506}\n",
      "{'loss': 0.2727, 'grad_norm': 1.8602861166000366, 'learning_rate': 4.155495978552279e-05, 'epoch': 9.584450402144771}\n",
      "{'loss': 0.2795, 'grad_norm': 27.291223526000977, 'learning_rate': 4.021447721179625e-05, 'epoch': 9.597855227882038}\n",
      "{'loss': 0.275, 'grad_norm': 28.006824493408203, 'learning_rate': 3.887399463806971e-05, 'epoch': 9.611260053619302}\n",
      "{'loss': 0.2494, 'grad_norm': 76.5805892944336, 'learning_rate': 3.753351206434316e-05, 'epoch': 9.624664879356569}\n",
      "{'loss': 0.2581, 'grad_norm': 13.956730842590332, 'learning_rate': 3.6193029490616625e-05, 'epoch': 9.638069705093834}\n",
      "{'loss': 0.3195, 'grad_norm': 6.912569999694824, 'learning_rate': 3.485254691689008e-05, 'epoch': 9.651474530831099}\n",
      "{'loss': 0.2654, 'grad_norm': 6.020565509796143, 'learning_rate': 3.351206434316354e-05, 'epoch': 9.664879356568365}\n",
      "{'loss': 0.3027, 'grad_norm': 27.793052673339844, 'learning_rate': 3.2171581769437e-05, 'epoch': 9.67828418230563}\n",
      "{'loss': 0.3097, 'grad_norm': 22.22637176513672, 'learning_rate': 3.083109919571045e-05, 'epoch': 9.691689008042896}\n",
      "{'loss': 0.2815, 'grad_norm': 0.3543081283569336, 'learning_rate': 2.9490616621983912e-05, 'epoch': 9.705093833780161}\n",
      "{'loss': 0.2879, 'grad_norm': 12.135053634643555, 'learning_rate': 2.8150134048257374e-05, 'epoch': 9.718498659517426}\n",
      "{'loss': 0.2584, 'grad_norm': 7.7932515144348145, 'learning_rate': 2.6809651474530833e-05, 'epoch': 9.731903485254692}\n",
      "{'loss': 0.2467, 'grad_norm': 31.790454864501953, 'learning_rate': 2.546916890080429e-05, 'epoch': 9.745308310991957}\n",
      "{'loss': 0.2855, 'grad_norm': 5.538557529449463, 'learning_rate': 2.4128686327077747e-05, 'epoch': 9.758713136729222}\n",
      "{'loss': 0.2796, 'grad_norm': 7.891055583953857, 'learning_rate': 2.278820375335121e-05, 'epoch': 9.772117962466488}\n",
      "{'loss': 0.2453, 'grad_norm': 1.4048659801483154, 'learning_rate': 2.1447721179624665e-05, 'epoch': 9.785522788203753}\n",
      "{'loss': 0.2334, 'grad_norm': 11.018500328063965, 'learning_rate': 2.0107238605898124e-05, 'epoch': 9.798927613941018}\n",
      "{'loss': 0.2791, 'grad_norm': 7.350050926208496, 'learning_rate': 1.876675603217158e-05, 'epoch': 9.812332439678285}\n",
      "{'loss': 0.2724, 'grad_norm': 15.035080909729004, 'learning_rate': 1.742627345844504e-05, 'epoch': 9.82573726541555}\n",
      "{'loss': 0.2931, 'grad_norm': 28.052995681762695, 'learning_rate': 1.60857908847185e-05, 'epoch': 9.839142091152816}\n",
      "{'loss': 0.3002, 'grad_norm': 30.164464950561523, 'learning_rate': 1.4745308310991956e-05, 'epoch': 9.85254691689008}\n",
      "{'loss': 0.2624, 'grad_norm': 26.443161010742188, 'learning_rate': 1.3404825737265417e-05, 'epoch': 9.865951742627345}\n",
      "{'loss': 0.269, 'grad_norm': 2.9239821434020996, 'learning_rate': 1.2064343163538874e-05, 'epoch': 9.879356568364612}\n",
      "{'loss': 0.2584, 'grad_norm': 10.87916088104248, 'learning_rate': 1.0723860589812333e-05, 'epoch': 9.892761394101877}\n",
      "{'loss': 0.2659, 'grad_norm': 33.35398864746094, 'learning_rate': 9.38337801608579e-06, 'epoch': 9.906166219839141}\n",
      "{'loss': 0.3074, 'grad_norm': 11.587930679321289, 'learning_rate': 8.04289544235925e-06, 'epoch': 9.919571045576408}\n",
      "{'loss': 0.2727, 'grad_norm': 32.75307083129883, 'learning_rate': 6.702412868632708e-06, 'epoch': 9.932975871313673}\n",
      "{'loss': 0.2862, 'grad_norm': 3.4636847972869873, 'learning_rate': 5.361930294906166e-06, 'epoch': 9.946380697050937}\n",
      "{'loss': 0.2638, 'grad_norm': 15.149977684020996, 'learning_rate': 4.021447721179625e-06, 'epoch': 9.959785522788204}\n",
      "{'loss': 0.2633, 'grad_norm': 16.280729293823242, 'learning_rate': 2.680965147453083e-06, 'epoch': 9.973190348525469}\n",
      "{'loss': 0.2575, 'grad_norm': 14.699287414550781, 'learning_rate': 1.3404825737265416e-06, 'epoch': 9.986595174262735}\n",
      "{'loss': 0.287, 'grad_norm': 16.548171997070312, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'eval_loss': 0.2766822278499603, 'eval_accuracy': 0.9109375, 'eval_runtime': 5.3603, 'eval_samples_per_second': 119.396, 'eval_steps_per_second': 1.866, 'epoch': 10.0}\n",
      "{'train_runtime': 20606.6045, 'train_samples_per_second': 57.923, 'train_steps_per_second': 3.62, 'train_loss': 0.32291672041844427, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "peft_lora_finetuning_trainer = get_trainer(peft_model)\n",
    "\n",
    "result = peft_lora_finetuning_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183be7e-514f-4e64-a6f4-314a827e6be5",
   "metadata": {
    "id": "5183be7e-514f-4e64-a6f4-314a827e6be5"
   },
   "source": [
    "## Evaluate Finetuned Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038198cf-0953-47e7-bd47-b073d05f8378",
   "metadata": {
    "id": "038198cf-0953-47e7-bd47-b073d05f8378"
   },
   "source": [
    "### Performing Inference on Custom Input\n",
    "Uncomment following functions for running inference on custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f88ad420-3f46-4eff-9d71-0ce388163062",
   "metadata": {
    "id": "f88ad420-3f46-4eff-9d71-0ce388163062"
   },
   "outputs": [],
   "source": [
    "def classify(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    output = model(**inputs)\n",
    "\n",
    "    prediction = output.logits.argmax(dim=-1).item()\n",
    "\n",
    "    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc52bb94-5e13-4943-9225-a6d7fd053579",
   "metadata": {
    "id": "fc52bb94-5e13-4943-9225-a6d7fd053579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class: 0, Label: World, Text: Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\n",
      "\n",
      " Class: 2, Label: Business, Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindlinand of ultra-cynics, are seeing green again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify( peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\n",
    "classify( peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf",
   "metadata": {
    "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf"
   },
   "source": [
    "### Run Inference on eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5",
   "metadata": {
    "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        inference_model: The model to evaluate.\n",
    "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
    "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
    "                         If False, only predictions will be returned.\n",
    "        batch_size (int): Batch size for inference.\n",
    "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
    "\n",
    "    Returns:\n",
    "        If labelled is True, returns a tuple (metrics, predictions)\n",
    "        If labelled is False, returns the predictions.\n",
    "    \"\"\"\n",
    "    # Create the DataLoader\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    if labelled:\n",
    "        metric = evaluate.load('accuracy')\n",
    "\n",
    "    # Loop over the DataLoader\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        # Move each tensor in the batch to the device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        all_predictions.append(predictions.cpu())\n",
    "\n",
    "        if labelled:\n",
    "            # Expecting that labels are provided under the \"labels\" key.\n",
    "            references = batch[\"labels\"]\n",
    "            metric.add_batch(\n",
    "                predictions=predictions.cpu().numpy(),\n",
    "                references=references.cpu().numpy()\n",
    "            )\n",
    "\n",
    "    # Concatenate predictions from all batches\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    if labelled:\n",
    "        eval_metric = metric.compute()\n",
    "        print(\"Evaluation Metric:\", eval_metric)\n",
    "        return eval_metric, all_predictions\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
   "metadata": {
    "id": "809635a6-a2c7-4d09-8d60-ababd1815003"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:06<00:00, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metric: {'accuracy': 0.9109375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check evaluation accuracy\n",
    "_, _ = evaluate_model(peft_model, eval_dataset, True, 8, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "kMJgvV1ZnVhd",
   "metadata": {
    "id": "kMJgvV1ZnVhd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 3, 0, 3, 0, 3, 3, 2, 1, 2, 3, 0, 2, 1, 1, 0, 3, 2, 3, 2, 2, 2,\n",
      "        0, 1, 3, 2, 1, 1, 3, 1, 0, 1, 2, 0, 0, 0, 2, 3, 0, 3, 1, 1, 2, 3, 0, 0,\n",
      "        0, 1, 3, 1, 0, 3, 1, 1, 3, 0, 3, 2, 3, 3, 0, 0, 1, 3, 1, 1, 1, 2, 0, 3,\n",
      "        2, 3, 2, 1, 1, 3, 1, 2, 0, 3, 2, 0, 1, 2, 2, 3, 1, 0, 1, 0, 3, 3, 2, 1,\n",
      "        2, 1, 2, 1, 2, 2, 2, 2, 1, 3, 0, 3, 1, 2, 3, 3, 0, 1, 2, 0, 1, 1, 2, 1,\n",
      "        0, 0, 3, 2, 3, 3, 3, 2, 1, 2, 3, 3, 2, 0, 3, 0, 0, 0, 1, 0, 3, 1, 0, 3,\n",
      "        0, 3, 0, 3, 0, 2, 1, 0, 0, 3, 3, 3, 2, 1, 3, 0, 0, 2, 0, 1, 3, 3, 3, 2,\n",
      "        3, 1, 1, 3, 2, 2, 0, 0, 2, 2, 3, 0, 1, 2, 1, 0, 2, 0, 1, 3, 2, 3, 0, 1,\n",
      "        2, 0, 0, 3, 3, 3, 1, 2, 1, 2, 2, 1, 3, 2, 2, 1, 0, 3, 3, 1, 0, 0, 0, 0,\n",
      "        0, 2, 0, 3, 2, 2, 0, 2, 3, 2, 3, 3, 3, 3, 3, 1, 0, 0, 3, 1, 1, 1, 2, 1,\n",
      "        3, 1, 1, 1, 2, 2, 3, 0, 1, 0, 2, 0, 1, 3, 1, 2, 2, 1, 3, 2, 0, 0, 0, 2,\n",
      "        1, 1, 0, 1, 3, 2, 1, 2, 2, 1, 0, 2, 1, 3, 2, 3, 0, 2, 2, 2, 2, 1, 2, 0,\n",
      "        1, 1, 3, 3, 1, 3, 0, 2, 1, 3, 0, 3, 1, 2, 3, 1, 3, 1, 0, 0, 3, 3, 3, 3,\n",
      "        3, 0, 3, 2, 3, 1, 1, 1, 0, 1, 3, 1, 1, 1, 3, 3, 2, 2, 3, 2, 3, 1, 0, 0,\n",
      "        3, 1, 2, 0, 0, 2, 3, 3, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 3, 0,\n",
      "        1, 1, 0, 1, 2, 1, 3, 3, 1, 0, 2, 0, 2, 3, 0, 1, 3, 3, 2, 0, 1, 1, 1, 1,\n",
      "        0, 3, 2, 1, 0, 2, 2, 2, 3, 1, 2, 3, 3, 1, 3, 3, 1, 0, 0, 1, 0, 3, 1, 1,\n",
      "        3, 0, 0, 0, 2, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 2, 2, 3, 1, 1, 3, 2, 1, 1,\n",
      "        1, 3, 3, 2, 3, 3, 1, 2, 3, 1, 3, 0, 0, 3, 3, 0, 3, 0, 1, 0, 2, 2, 2, 2,\n",
      "        0, 1, 0, 3, 2, 1, 1, 2, 3, 0, 3, 3, 3, 3, 0, 2, 1, 0, 1, 3, 2, 2, 3, 3,\n",
      "        1, 0, 0, 1, 3, 0, 2, 1, 3, 1, 3, 2, 3, 3, 2, 2, 2, 1, 3, 3, 3, 1, 2, 2,\n",
      "        2, 0, 2, 2, 1, 3, 3, 1, 3, 2, 3, 2, 0, 3, 2, 0, 3, 3, 3, 2, 0, 1, 0, 1,\n",
      "        2, 2, 3, 0, 3, 3, 2, 3, 0, 2, 3, 0, 3, 2, 0, 3, 1, 0, 3, 2, 3, 0, 0, 1,\n",
      "        2, 0, 3, 2, 3, 0, 1, 3, 3, 3, 3, 1, 2, 2, 0, 3, 1, 0, 2, 0, 0, 2, 3, 0,\n",
      "        3, 3, 2, 2, 3, 0, 2, 2, 1, 3, 2, 0, 3, 0, 1, 0, 2, 1, 3, 0, 1, 1, 2, 2,\n",
      "        3, 2, 3, 3, 0, 0, 1, 1, 1, 0, 0, 1, 2, 3, 0, 0, 3, 2, 3, 2, 3, 1, 1, 2,\n",
      "        3, 0, 2, 3, 3, 0, 3, 1, 3, 3, 2, 2, 1, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203",
   "metadata": {
    "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203"
   },
   "source": [
    "### Run Inference on unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7",
   "metadata": {
    "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8000/8000 [00:05<00:00, 1376.78 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load your unlabelled data\n",
    "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
    "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "unlabelled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e60991d3-38b1-4657-8854-408ce66f6b84",
   "metadata": {
    "id": "e60991d3-38b1-4657-8854-408ce66f6b84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:02<00:00, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Predictions saved to inference_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference and save predictions\n",
    "preds = evaluate_model(peft_model, test_dataset, False, 8, data_collator)\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(preds)),\n",
    "    'Label': preds.numpy()  # or preds.tolist()\n",
    "})\n",
    "df_output.to_csv(os.path.join(output_dir,\"inference_output_1.csv\"), index=False)\n",
    "print(\"Inference complete. Predictions saved to inference_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a992a98-5d72-431c-b602-7f74de67c262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
